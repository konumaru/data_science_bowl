{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rui/.local/share/virtualenvs/data_science_bowl-_c7OiX6v/lib/python3.8/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/rui/.local/share/virtualenvs/data_science_bowl-_c7OiX6v/lib/python3.8/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_selection.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import re\n",
    "import abc\n",
    "import json\n",
    "import copy\n",
    "import time\n",
    "import eli5\n",
    "import datetime\n",
    "from numba import jit, jitclass\n",
    "from numba import int32, float32\n",
    "from pathlib import Path\n",
    "\n",
    "from IPython.display import HTML\n",
    "import altair as alt\n",
    "from category_encoders.ordinal import OrdinalEncoder\n",
    "from typing import List, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "import shap\n",
    "\n",
    "from itertools import product\n",
    "from functools import partial\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import NuSVR, SVR\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import cohen_kappa_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "from time import time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('max_rows', 500)\n",
    "pd.options.display.precision = 15\n",
    "np.random.seed(42)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "source": [
    "# Objective\n",
    "\n",
    "- 特徴量の追加を行う。\n",
    "- 具体的には、以下のような特徴量を追加する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "\n",
    "    \n",
    "## Scores\n",
    "- baseline\n",
    "    - OOF: 0.5887003970727024\n",
    "    - Truncated OOF QWK: 0.5489\n",
    "- GroupK CV, weighted RMSE\n",
    "    - OOF: 0.5873471117473519\n",
    "    - Truncated OOF QWK: 0.5574"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train ....\n",
      "train file have 11341042 rows and 11 columns.\n",
      "Reading test ....\n",
      "test file have 1156414 rows and 11 columns.\n",
      "Reading sample_submission ....\n",
      "sample_submission file have 1000 rows and 2 columns.\n"
     ]
    }
   ],
   "source": [
    "def read_data(files: list):\n",
    "    if os.path.exists('/kaggle/input/data-science-bowl-2019/'):\n",
    "        data_dir_path = '/kaggle/input/data-science-bowl-2019/'\n",
    "    else:\n",
    "        data_dir_path = '../data/reduced/'\n",
    "    \n",
    "    dst_data = {}\n",
    "    for file in files:\n",
    "        print(f'Reading {file} ....')\n",
    "        dst_data[file] = pd.read_pickle(data_dir_path + file + '.pkl')\n",
    "        print(f'{file} file have {dst_data[file].shape[0]} rows and {dst_data[file].shape[1]} columns.')\n",
    "    return dst_data.values()\n",
    "\n",
    "\n",
    "# 'sample_submission.csv', 'specs.csv', 'test.csv', 'train_labels.csv', 'train.csv'\n",
    "raw_train, raw_test, sample_submission = read_data(['train', 'test', 'sample_submission'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11341042, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>game_session</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>event_data</th>\n",
       "      <th>installation_id</th>\n",
       "      <th>event_count</th>\n",
       "      <th>event_code</th>\n",
       "      <th>game_time</th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>world</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27253bdc</td>\n",
       "      <td>45bb1e1b6b50c07b</td>\n",
       "      <td>2019-09-06T17:53:46.937Z</td>\n",
       "      <td>{\"event_code\": 2000, \"event_count\": 1}</td>\n",
       "      <td>0001e90f</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>Welcome to Lost Lagoon!</td>\n",
       "      <td>Clip</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27253bdc</td>\n",
       "      <td>17eeb7f223665f53</td>\n",
       "      <td>2019-09-06T17:54:17.519Z</td>\n",
       "      <td>{\"event_code\": 2000, \"event_count\": 1}</td>\n",
       "      <td>0001e90f</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>Magma Peak - Level 1</td>\n",
       "      <td>Clip</td>\n",
       "      <td>MAGMAPEAK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77261ab5</td>\n",
       "      <td>0848ef14a8dc6892</td>\n",
       "      <td>2019-09-06T17:54:56.302Z</td>\n",
       "      <td>{\"version\":\"1.0\",\"event_count\":1,\"game_time\":0...</td>\n",
       "      <td>0001e90f</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>Sandcastle Builder (Activity)</td>\n",
       "      <td>Activity</td>\n",
       "      <td>MAGMAPEAK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b2dba42b</td>\n",
       "      <td>0848ef14a8dc6892</td>\n",
       "      <td>2019-09-06T17:54:56.387Z</td>\n",
       "      <td>{\"description\":\"Let's build a sandcastle! Firs...</td>\n",
       "      <td>0001e90f</td>\n",
       "      <td>2</td>\n",
       "      <td>3010</td>\n",
       "      <td>53</td>\n",
       "      <td>Sandcastle Builder (Activity)</td>\n",
       "      <td>Activity</td>\n",
       "      <td>MAGMAPEAK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1bb5fbdb</td>\n",
       "      <td>0848ef14a8dc6892</td>\n",
       "      <td>2019-09-06T17:55:03.253Z</td>\n",
       "      <td>{\"description\":\"Let's build a sandcastle! Firs...</td>\n",
       "      <td>0001e90f</td>\n",
       "      <td>3</td>\n",
       "      <td>3110</td>\n",
       "      <td>6972</td>\n",
       "      <td>Sandcastle Builder (Activity)</td>\n",
       "      <td>Activity</td>\n",
       "      <td>MAGMAPEAK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_id      game_session                 timestamp  \\\n",
       "0  27253bdc  45bb1e1b6b50c07b  2019-09-06T17:53:46.937Z   \n",
       "1  27253bdc  17eeb7f223665f53  2019-09-06T17:54:17.519Z   \n",
       "2  77261ab5  0848ef14a8dc6892  2019-09-06T17:54:56.302Z   \n",
       "3  b2dba42b  0848ef14a8dc6892  2019-09-06T17:54:56.387Z   \n",
       "4  1bb5fbdb  0848ef14a8dc6892  2019-09-06T17:55:03.253Z   \n",
       "\n",
       "                                          event_data installation_id  \\\n",
       "0             {\"event_code\": 2000, \"event_count\": 1}        0001e90f   \n",
       "1             {\"event_code\": 2000, \"event_count\": 1}        0001e90f   \n",
       "2  {\"version\":\"1.0\",\"event_count\":1,\"game_time\":0...        0001e90f   \n",
       "3  {\"description\":\"Let's build a sandcastle! Firs...        0001e90f   \n",
       "4  {\"description\":\"Let's build a sandcastle! Firs...        0001e90f   \n",
       "\n",
       "   event_count  event_code  game_time                          title  \\\n",
       "0            1        2000          0        Welcome to Lost Lagoon!   \n",
       "1            1        2000          0           Magma Peak - Level 1   \n",
       "2            1        2000          0  Sandcastle Builder (Activity)   \n",
       "3            2        3010         53  Sandcastle Builder (Activity)   \n",
       "4            3        3110       6972  Sandcastle Builder (Activity)   \n",
       "\n",
       "       type      world  \n",
       "0      Clip       NONE  \n",
       "1      Clip  MAGMAPEAK  \n",
       "2  Activity  MAGMAPEAK  \n",
       "3  Activity  MAGMAPEAK  \n",
       "4  Activity  MAGMAPEAK  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(raw_train.shape)\n",
    "raw_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creat Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted(list(set(raw_train['event_code'].tolist()) & set(raw_test['event_code'].tolist())))\n",
    "all_event_code = [\n",
    "    2000, 2010, 2020, 2025, 2030, 2035, 2040, 2050, 2060, 2070, 2075, 2080, 2081, 2083, \n",
    "    3010, 3020, 3021, 3110, 3120, 3121, 4010, 4020, 4021, 4022, 4025, 4030, 4031, 4035, \n",
    "    4040, 4045, 4050, 4070, 4080, 4090, 4095, 4100, 4110, 4220, 4230, 4235, 5000, 5010\n",
    "]\n",
    "all_title = [\n",
    "    '12 Monkeys', 'Air Show', 'All Star Sorting', 'Balancing Act', 'Bird Measurer (Assessment)', \n",
    "    'Bottle Filler (Activity)', 'Bubble Bath', 'Bug Measurer (Activity)', 'Cart Balancer (Assessment)', \n",
    "    'Cauldron Filler (Assessment)', 'Chest Sorter (Assessment)', 'Chicken Balancer (Activity)', \n",
    "    'Chow Time', 'Costume Box', 'Crystal Caves - Level 1', 'Crystal Caves - Level 2', \n",
    "    'Crystal Caves - Level 3', 'Crystals Rule', 'Dino Dive', 'Dino Drink', 'Egg Dropper (Activity)', \n",
    "    'Fireworks (Activity)', 'Flower Waterer (Activity)', 'Happy Camel', 'Heavy, Heavier, Heaviest', \n",
    "    'Honey Cake', 'Leaf Leader', 'Lifting Heavy Things', 'Magma Peak - Level 1', 'Magma Peak - Level 2', \n",
    "    'Mushroom Sorter (Assessment)', 'Ordering Spheres', 'Pan Balance', \"Pirate's Tale\", 'Rulers', \n",
    "    'Sandcastle Builder (Activity)', 'Scrub-A-Dub', 'Slop Problem', 'Treasure Map', 'Tree Top City - Level 1', \n",
    "    'Tree Top City - Level 2', 'Tree Top City - Level 3', 'Watering Hole (Activity)', 'Welcome to Lost Lagoon!'\n",
    "]\n",
    "all_type = ['Activity', 'Assessment', 'Clip', 'Game']\n",
    "all_world = ['CRYSTALCAVES', 'MAGMAPEAK', 'NONE', 'TREETOPCITY']\n",
    "\n",
    "assessment_title = [\n",
    "    'Bird Measurer (Assessment)', 'Cart Balancer (Assessment)', 'Cauldron Filler (Assessment)', \n",
    "    'Chest Sorter (Assessment)', 'Mushroom Sorter (Assessment)'\n",
    "]\n",
    "\n",
    "\n",
    "assessment_title_map = {l: i for i, l in enumerate(assessment_title)}\n",
    "all_type_map = {l: i for i, l in enumerate(all_type)}\n",
    "all_world_map = {l: i for i, l in enumerate(all_world)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature(metaclass=abc.ABCMeta):\n",
    "    prefix = \"\"\n",
    "    suffix = \"\"\n",
    "    save_dir = \"features\"\n",
    "    is_feature = True\n",
    "\n",
    "    def __init__(self):\n",
    "        self.name = self.__class__.__name__\n",
    "        Path(self.save_dir).mkdir(exist_ok=True, parents=True)\n",
    "        self.train = pd.DataFrame()\n",
    "        self.test = pd.DataFrame()\n",
    "        self.categoricals = pd.Series()\n",
    "        self.train_path = Path(self.save_dir) / f\"{self.name}_train.pkl\"\n",
    "        self.test_path = Path(self.save_dir) / f\"{self.name}_test.pkl\"\n",
    "        self.categoricals_path = Path(self.save_dir) / f\"{self.name}_categoricals.pkl\"\n",
    "\n",
    "    def run(self, train_df, test_df=None, log=False):\n",
    "        self.create_features(train_df, test_df)\n",
    "        prefix = self.prefix + \"_\" if self.prefix else \"\"\n",
    "        suffix = self.suffix + \"_\" if self.suffix else \"\"\n",
    "        self.train.columns = pd.Index([str(c) for c in self.train.columns])\n",
    "        self.test.columns = pd.Index([str(c) for c in self.test.columns])\n",
    "        self.train.columns = prefix + self.train.columns + suffix\n",
    "        self.test.columns = prefix + self.test.columns + suffix\n",
    "        return self\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def create_features(self, train_df, test_df):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def save(self):\n",
    "        self.train.to_pickle(str(self.train_path))\n",
    "        self.test.to_pickle(str(self.test_path))\n",
    "        self.categoricals.to_pickle(str(self.categoricals_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "## Abbreviations\n",
    "- sess -> session, game_session\n",
    "- ins_id -> installation_id\n",
    "- acc -> accuracy\n",
    "- pre -> previous\n",
    "\"\"\"\n",
    "class PastSessSummary(Feature):\n",
    "    # accuracy_groupの算出\n",
    "    def cal_accuracy_group(self, accuracy):\n",
    "        if accuracy == 0:\n",
    "            return 0\n",
    "        elif accuracy == 1:\n",
    "            return 3\n",
    "        elif accuracy == 0.5:\n",
    "            return 2\n",
    "        else:\n",
    "            return 1\n",
    "        \n",
    "    # session単位のデータから特徴量を作成する。\n",
    "    def get_data(self, ins_id, user_sample, is_test=False):\n",
    "        all_assessments = []\n",
    "        # 全過去セッションのcount・sum系特徴量\n",
    "        past_event_codes = []\n",
    "        title_count = {i: 0.0 for i in all_title}\n",
    "        type_count = {i: 0.0 for i in all_type}\n",
    "        world_count = {i: 0.0 for i in all_world}\n",
    "        type_sess_time = {i: [] for i in all_type}\n",
    "        type_event_count = {i: [] for i in all_type}\n",
    "        # 過去Assessmentの平均・カウントデータ\n",
    "        past_all_assessments = []        \n",
    "        acc_group_count = {f'acc_group_cnt_of_{i}': 0 for i in range(4)}\n",
    "        avg_acc_group = 0\n",
    "        avg_acc = 0\n",
    "        avg_num_correct = 0\n",
    "        avg_num_incorrect = 0\n",
    "        avg_num_attempt = 0\n",
    "        # 直前のセッションの特徴量\n",
    "        pre_title = 'None'\n",
    "        pre_world = 'None'\n",
    "        pre_acc_each_title = {f'previous_acc_of_{t}': -1 for t in assessment_title}\n",
    "        pre_sess_time_title = {f'pre_session_time_of_{title}': -1 for title in all_title}\n",
    "        pre_sess_time = -1\n",
    "        # Game セッションの特徴量\n",
    "        game_sess_keys = [\n",
    "            'game_num_correct', 'game_num_incorrect', 'game_num_attempt', 'game_accuracy',\n",
    "            'game_num_event_count', 'game_sess_time', 'game_round', 'game_sum_misses'\n",
    "        ]\n",
    "        game_sess_feats = {k: [] for k in game_sess_keys}\n",
    "        \n",
    "        game_num_correct = []\n",
    "        game_num_incorrect = []\n",
    "        game_num_attempt = []\n",
    "        game_accuracy = []\n",
    "        game_num_event_count =[]\n",
    "        game_sess_time = []\n",
    "        game_round = []\n",
    "        game_sum_misses = []\n",
    "\n",
    "        \n",
    "        # Parse Session Data\n",
    "        for n_sess, (game_sess, sess) in enumerate(user_sample.groupby('game_session', sort=False)):\n",
    "            sess_title = sess['title'].iloc[0]\n",
    "            sess_type = sess['type'].iloc[0]\n",
    "            sess_world = sess['world'].iloc[0]\n",
    "            sess_time = sess['game_time'].iloc[-1]\n",
    "            sess_event_count = sess['event_count'].iloc[-1]\n",
    "            event_codes = sess['event_code'].tolist()\n",
    "            \n",
    "            # Parse Assessment Session \n",
    "            if (sess_type == \"Assessment\") & (is_test or len(sess)>1):\n",
    "                attempt_code = 4110 if sess_title == \"Bird Measurer (Assessment)\" else 4100\n",
    "                all_attempts = sess.query(f\"event_code == {attempt_code}\")\n",
    "                \n",
    "                num_correct = all_attempts[\"event_data\"].str.contains('\"correct\":true').sum()\n",
    "                num_incorrect = all_attempts[\"event_data\"].str.contains('\"correct\":false').sum()\n",
    "\n",
    "                num_attempt = num_correct + num_incorrect\n",
    "                accuracy = round(num_correct / num_attempt, 4) if num_attempt != 0 else 0\n",
    "                accuracy_group = self.cal_accuracy_group(accuracy)\n",
    "                # Initialize And Create Features\n",
    "                features = {}\n",
    "                features.update({\n",
    "                    'game_session': game_sess,\n",
    "                    'installation_id': ins_id,\n",
    "                    'sess_title': sess_title,\n",
    "                    'accuracy_group': accuracy_group,\n",
    "                    'num_past_attemmpt_assessment': len(past_all_assessments),\n",
    "                    'nunique_past_attemmpt_assessment': len(set(past_all_assessments)),\n",
    "                    'AVG_acc_group': avg_acc_group,\n",
    "                    'AVG_acc': avg_acc,\n",
    "                    'AVG_num_correct': avg_num_correct,\n",
    "                    'AVG_num_incorrect': avg_num_incorrect,\n",
    "                    'AVG_num_attempt': avg_num_attempt,\n",
    "                    'pre_title': sess_title,\n",
    "                    'pre_world': sess_world,\n",
    "                    'pre_sess_time': pre_sess_time\n",
    "                })\n",
    "                features.update(Counter(past_event_codes))\n",
    "                features.update(title_count)\n",
    "                features.update(type_count)\n",
    "                features.update(world_count)\n",
    "                features.update(pre_acc_each_title)\n",
    "                features.update(acc_group_count)\n",
    "                features.update({f'avg_past_{t}_session_time': np.mean(vals) for t, vals in type_sess_time.items()})\n",
    "                features.update({f'sum_past_{t}_session_time': np.sum(vals) for t, vals in type_sess_time.items()})\n",
    "                features.update({f'avg_past_{t}_event_count': np.mean(vals) for t, vals in type_event_count.items()})\n",
    "                features.update({f'sum_past_{t}_event_count': np.sum(vals) for t, vals in type_event_count.items()})\n",
    "                features.update(pre_sess_time_title)\n",
    "                # add game features\n",
    "                for key, val in game_sess_feats.items():\n",
    "                    features.update({\n",
    "                        f'MIN_{key}': np.min(val) if len(val)>0 else 0,\n",
    "                        f'MAX_{key}': np.max(val) if len(val)>0 else 0,\n",
    "                        f'AVG_{key}': np.mean(val) if len(val)>0 else 0,\n",
    "                        f'STD_{key}': np.std(val) if len(val)>0 else 0,\n",
    "                        f'SUM_{key}': np.sum(val) if len(val)>0 else 0\n",
    "                    })\n",
    "                \n",
    "                if is_test:\n",
    "                    all_assessments.append(features)\n",
    "                elif num_attempt > 0:\n",
    "                    all_assessments.append(features)\n",
    "                \n",
    "                # --------------------------------------------------------------------------------\n",
    "                # Assessment特徴量の更新\n",
    "                past_all_assessments.append(sess_title)\n",
    "                pre_acc_each_title[f'previous_acc_of_{sess_title}'] = accuracy\n",
    "                acc_group_count[f'acc_group_cnt_of_{accuracy_group}'] += 1\n",
    "                avg_acc_group = (avg_acc_group + accuracy_group) / n_sess if n_sess!=0 else 0\n",
    "                avg_acc = (avg_acc + accuracy) / n_sess if n_sess!=0 else 0\n",
    "                avg_num_correct = (avg_num_correct + num_correct) / n_sess if n_sess!=0 else 0\n",
    "                avg_num_incorrect = (avg_num_incorrect + num_incorrect) / n_sess if n_sess!=0 else 0\n",
    "                avg_num_attempt = (avg_num_attempt + num_attempt) / n_sess if n_sess!=0 else 0\n",
    "                \n",
    "            if sess_type=='Game':\n",
    "                g_num_correct = sess['event_data'].str.contains('\"correct\":true').astype(int).sum()\n",
    "                g_num_incorrect = sess['event_data'].str.contains('\"correct\":false').astype(int).sum()\n",
    "                g_num_attempt = g_num_correct + g_num_incorrect\n",
    "                g_accuracy = g_num_correct / g_num_attempt if g_num_attempt!=0 else -1\n",
    "                g_round = sess[sess['event_data'].str.contains('round')]['event_data'].str.extract('.\"round\":(\\w).').max()[0]\n",
    "                g_misses = sess[sess['event_data'].str.contains('round')]['event_data'].str.extract('.\"misses\":(\\w).').sum()\n",
    "                g_misses = g_misses[0] if len(g_misses)>0 else 0\n",
    "                \n",
    "                game_sess_feats['game_num_correct'].append(g_num_correct)\n",
    "                game_sess_feats['game_num_incorrect'].append(g_num_incorrect)\n",
    "                game_sess_feats['game_num_attempt'].append(g_num_attempt)\n",
    "                game_sess_feats['game_accuracy'].append(g_accuracy)\n",
    "                game_sess_feats['game_num_event_count'].append(len(event_codes))\n",
    "                game_sess_feats['game_sess_time'].append(sess_time)\n",
    "                game_sess_feats['game_round'].append(g_round)\n",
    "                game_sess_feats['game_sum_misses'].append(g_misses)\n",
    "            \n",
    "                    \n",
    "            # All Session Feature\n",
    "            past_event_codes.extend(event_codes)\n",
    "            title_count[sess_title] += 1\n",
    "            type_count[sess_type] += 1\n",
    "            world_count[sess_world] += 1\n",
    "            type_sess_time[sess_type].append(sess_time)\n",
    "            type_event_count[sess_type].append(sess_event_count)\n",
    "            pre_title = sess_title\n",
    "            pre_world = sess_world\n",
    "            pre_sess_time_title[sess_title] = sess_time\n",
    "            pre_sess_time = sess_time\n",
    "    \n",
    "        return all_assessments\n",
    "        \n",
    "    \n",
    "    # installation_idでgroupbyする役割を持ちデータをclass変数に割り当てる。\n",
    "    def create_features(self, train, test):\n",
    "        compiled_train = []\n",
    "        compiled_test = []\n",
    "        \n",
    "        for ins_id, user_sample in tqdm(train.groupby('installation_id', sort=False)):\n",
    "            compiled_train += self.get_data(ins_id, user_sample)\n",
    "        \n",
    "        for ins_id, user_sample in tqdm(test.groupby('installation_id', sort = False)):\n",
    "            compiled_test += self.get_data(ins_id, user_sample, is_test=True)\n",
    "        \n",
    "        train = pd.DataFrame(compiled_train)\n",
    "        test = pd.DataFrame(compiled_test) \n",
    "\n",
    "        categoricals = ['sess_title', 'pre_title', 'pre_world']\n",
    "        for c in categoricals:\n",
    "            unique_val = list( set(train[c].tolist()) | set(test[c].tolist()) )\n",
    "            le = LabelEncoder().fit(unique_val)\n",
    "            train[c] = le.transform(train[c])\n",
    "            test[c] = le.transform(test[c])\n",
    "        \n",
    "        self.train = train\n",
    "        self.test = test\n",
    "        self.categoricals = pd.Series(categoricals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38604eed3aa94b16be67496b9d720ee6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "PastSessSummary().run(raw_train, raw_test).save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Feature\n",
    "reduced_train = pd.read_pickle('./features/PastSessSummary_train.pkl')\n",
    "reduced_test = pd.read_pickle('./features/PastSessSummary_test.pkl').drop_duplicates(subset='installation_id', keep='last')\n",
    "categoricals = pd.read_pickle('./features/PastSessSummary_categoricals.pkl').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train_size: ', reduced_train.shape)\n",
    "print('test_size: ', reduced_test.shape)\n",
    "reduced_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename Columns For LightGBM\n",
    "reduced_train.columns = [\"\".join(c if c.isalnum() else \"_\" for c in str(x)) for x in reduced_train.columns]\n",
    "reduced_test.columns = [\"\".join(c if c.isalnum() else \"_\" for c in str(x)) for x in reduced_test.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Feature\n",
    "features = reduced_train.loc[(reduced_train.sum(axis=1) != 0), (reduced_train.sum(axis=0) != 0)].columns\n",
    "features = [x for x in features \n",
    "            if x not in [\n",
    "                'game_session', 'installation_id', 'num_correct', 'num_incorrect', 'accuracy_group',\n",
    "                'accuracy', 'game_time']\n",
    "           ]\n",
    "\n",
    "\n",
    "# Reduce Feature\n",
    "to_remove = []\n",
    "to_exclude = []\n",
    "\n",
    "\n",
    "# Drop High Correlation\n",
    "def get_high_corr(df, features, verbose=False):\n",
    "    drop_cols = []\n",
    "    counter = 0\n",
    "    for feat_a in features:\n",
    "        for feat_b in features:\n",
    "            if feat_a != feat_b and feat_a not in drop_cols and feat_b not in drop_cols:\n",
    "                corr = np.corrcoef(df[feat_a], df[feat_b])[0][1]\n",
    "                if corr > 0.995:\n",
    "                    counter += 1\n",
    "                    drop_cols.append(feat_b)\n",
    "                    if verbose:\n",
    "                        print(f'{counter}: {feat_a} {feat_b} - Correlation: {corr}')\n",
    "    return drop_cols\n",
    "\n",
    "to_remove += get_high_corr(reduced_train, features)\n",
    "\n",
    "\n",
    "\n",
    "# Manual Reduced Feature\n",
    "\n",
    "## Null importance\n",
    "## https://qiita.com/KenkenGoda/items/1d6ede5d492d1a9dc3c9\n",
    "## https://www.kaggle.com/ogrellier/feature-selection-with-null-importances\n",
    "\n",
    "\n",
    "# Remove Feature\n",
    "categoricals = [x for x in categoricals if x not in (to_exclude + to_remove)]\n",
    "features = [x for x in features if x not in (to_exclude + to_remove)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def qwk3(a1, a2, num_class=4):\n",
    "    assert(len(a1) == len(a2))\n",
    "    a1 = np.asarray(a1, dtype=int)\n",
    "    a2 = np.asarray(a2, dtype=int)\n",
    "\n",
    "    hist1 = np.zeros((num_class, ))\n",
    "    hist2 = np.zeros((num_class, ))\n",
    "\n",
    "    o = 0\n",
    "    for k in range(a1.shape[0]):\n",
    "        i, j = a1[k], a2[k]\n",
    "        hist1[i] += 1\n",
    "        hist2[j] += 1\n",
    "        o +=  (i - j) * (i - j)\n",
    "\n",
    "    e = 0\n",
    "    for i in range(num_class):\n",
    "        for j in range(num_class):\n",
    "            e += hist1[i] * hist2[j] * (i - j) * (i - j)\n",
    "\n",
    "    e = e / a1.shape[0]\n",
    "    return 1 - o / e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizedRounder(object):\n",
    "    def __init__(self, num_class=4):\n",
    "        self.coef_ = 0\n",
    "        self.initial_coef = [i for i in np.arange(1, (num_class+1)/2, 0.5)]\n",
    "        self.labels = [i for i in range(num_class)]\n",
    "    \n",
    "    def _kappa_loss(self, coef, X, y):\n",
    "        preds = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels=self.labels)\n",
    "        return -qwk3(y, preds)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        loss_partial = partial(self._kappa_loss, X = X, y = y)\n",
    "        initial_coef = self.initial_coef\n",
    "        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method = 'nelder-mead')\n",
    "    \n",
    "    def predict(self, X):\n",
    "        coef = self.coefficients()\n",
    "        preds = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels=self.labels)\n",
    "        return preds\n",
    "    \n",
    "    def coefficients(self):\n",
    "        return self.coef_['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def lgb_reg_qwk(y_pred:np.ndarray, data:lgb.Dataset):\n",
    "    y_true = data.get_label()\n",
    "\n",
    "    OptR = OptimizedRounder(num_class=4)\n",
    "    OptR.fit(y_pred, y_true)\n",
    "    y_pred = OptR.predict(y_pred).astype(int)\n",
    "    # name, result, is_higher_better\n",
    "    return \"qwk\", qwk3(y_true, y_pred), True\n",
    "\n",
    "@jit\n",
    "def lgb_regression_rmse(y_pred:np.ndarray, data:lgb.Dataset):\n",
    "    y_true = data.get_label()\n",
    "    return \"rmse\", np.sqrt(mean_squared_error(y_true, y_pred)), False\n",
    "\n",
    "@jit\n",
    "def lgb_weighted_rmse(y_pred:np.ndarray, data:lgb.Dataset):\n",
    "    y_true = data.get_label()\n",
    "    weight = data.get_weight()\n",
    "    return \"rmse\", np.sqrt(mean_squared_error(y_true, y_pred, sample_weight=weight)), False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Base_Model(object):\n",
    "    \n",
    "    def __init__(self, train_df, test_df, features, categoricals=[], \n",
    "                 n_splits=5, cv_method='StratifiedKFold', verbose=True, ps={}, custom_eval=None, weight=None):\n",
    "        self.train_df = train_df\n",
    "        self.test_df = test_df\n",
    "        self.features = features\n",
    "        self.n_splits = n_splits\n",
    "        self.categoricals = categoricals\n",
    "        self.target = 'accuracy_group'\n",
    "        self.groups = 'installation_id'\n",
    "        self.cv = self.get_cv(cv_method)\n",
    "        self.verbose = verbose\n",
    "        self.params = self.set_params(ps)\n",
    "        self.custom_eval = custom_eval\n",
    "        self.weight = weight\n",
    "        self.oof_pred, self.y_pred, self.score, self.models = self.fit()\n",
    "        \n",
    "    def train_model(self, train_set, val_set):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def get_cv(self, cv_method):\n",
    "        method = cv_method\n",
    "        if method=='StratifiedKFold':\n",
    "            cv = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=42)\n",
    "            return cv.split(self.train_df, self.train_df[self.target])\n",
    "        elif method=='GroupKFold':\n",
    "            cv = GroupKFold(n_splits=self.n_splits)\n",
    "            return cv.split(self.train_df, self.train_df[self.target], self.train_df[self.groups])\n",
    "    \n",
    "    def get_params(self):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def convert_dataset(self, x_train, y_train, x_val, y_val):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def convert_x(self, x):\n",
    "        return x\n",
    "        \n",
    "    def fit(self):\n",
    "        oof_pred = np.zeros((len(self.train_df), ))\n",
    "        y_pred = np.zeros((len(self.test_df), ))\n",
    "        models = []\n",
    "        \n",
    "        for fold, (train_idx, valid_idx) in enumerate(self.cv):\n",
    "            x_train, y_train = self.train_df[self.features].iloc[train_idx], self.train_df[self.target][train_idx]\n",
    "            x_valid, y_valid = self.train_df[self.features].iloc[valid_idx], self.train_df[self.target][valid_idx]\n",
    "            \n",
    "            train_set, valid_set = self.convert_dataset(x_train, y_train, x_valid, y_valid)\n",
    "            \n",
    "            # additonal process, Weight validation data only\n",
    "            if self.weight is not None:\n",
    "                valid_set = self.set_weight(valid_set, self.weight[valid_idx])\n",
    "                \n",
    "            model = self.train_model(train_set, valid_set)\n",
    "            models.append(model)\n",
    "            \n",
    "            conv_x_val = self.convert_x(x_valid)\n",
    "            oof_pred[valid_idx] = model.predict(conv_x_val).reshape(oof_pred[valid_idx].shape)\n",
    "            x_test = self.convert_x(self.test_df[self.features])\n",
    "            y_pred += model.predict(x_test).reshape(y_pred.shape) / self.n_splits\n",
    "            print(f'Partial score of fold {fold} is: {qwk3(y_valid, oof_pred[valid_idx])}\\n')\n",
    "            \n",
    "        loss_score = qwk3(self.train_df[self.target], oof_pred)\n",
    "        if self.verbose:\n",
    "            print(f'\\nOur oof cohen kappa score is: {loss_score}\\n')\n",
    "            \n",
    "        return oof_pred, y_pred, loss_score, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lgb_Model(Base_Model):\n",
    "    \n",
    "    def train_model(self, train_set, val_set):\n",
    "        verbosity = 100 if self.verbose else 0\n",
    "        return lgb.train(self.params, train_set, valid_sets=[train_set, val_set], verbose_eval=verbosity, feval=self.custom_eval)\n",
    "        \n",
    "    def convert_dataset(self, x_train, y_train, x_valid, y_valid):\n",
    "        train_set = lgb.Dataset(x_train, y_train, categorical_feature=self.categoricals)\n",
    "        valid_set = lgb.Dataset(x_valid, y_valid, categorical_feature=self.categoricals)\n",
    "        return train_set, valid_set\n",
    "    \n",
    "    def set_weight(self, data, weight):\n",
    "        return data.set_weight(weight)\n",
    "        \n",
    "    def get_params(self):\n",
    "        params = {\n",
    "            'n_estimators':5000,\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'regression',\n",
    "            'metric': 'rmse',\n",
    "            'subsample': 0.75,\n",
    "            'subsample_freq': 1,\n",
    "            'learning_rate': 0.03,\n",
    "            'feature_fraction': 0.8,\n",
    "            'max_depth': 7,\n",
    "            'num_leaves': 2**4,\n",
    "            'min_data_in_leaf': 50,\n",
    "            'lambda_l1': 1,  \n",
    "            'lambda_l2': 1,\n",
    "            \"n_jobs\": -1,\n",
    "            'early_stopping_rounds': 100\n",
    "        }\n",
    "        return params\n",
    "                                                                        \n",
    "    def set_params(self,ps={}):\n",
    "        params = self.get_params()\n",
    "        if 'subsample_freq' in ps:\n",
    "            params['subsample_freq']=int(ps['subsample_freq'])\n",
    "            params['learning_rate']=ps['learning_rate']\n",
    "            params['feature_fraction']=ps['feature_fraction']\n",
    "            params['lambda_l1']=ps['lambda_l1']\n",
    "            params['lambda_l2']=ps['lambda_l2']\n",
    "            params['max_depth']=int(ps['max_depth'])\n",
    "        \n",
    "        return params    \n",
    "    \n",
    "    def get_feature_importance(self, models):\n",
    "        feature_importance = pd.DataFrame(\n",
    "            [model.feature_importance() for model in models],\n",
    "            columns=models[0].feature_name()\n",
    "        ).T\n",
    "\n",
    "        feature_importance['Agerage_Importance'] = feature_importance.iloc[:, :len(models)].mean(axis=1)\n",
    "        feature_importance['importance_std'] = feature_importance.iloc[:, :len(models)].std(axis=1)\n",
    "        feature_importance.sort_values(by='Agerage_Importance', inplace=True)\n",
    "        return feature_importance\n",
    "    \n",
    "    def plot_importance(self, models, max_num_features=50, figsize=(12, 15)):\n",
    "        feature_importance = self.get_feature_importance(models)\n",
    "        plt.figure(figsize=figsize)\n",
    "        \n",
    "        feature_importance[-max_num_features:].plot(\n",
    "            kind='barh', title='Feature importance', figsize=figsize,\n",
    "            y='Agerage_Importance', xerr='importance_std',\n",
    "            grid=True, align=\"center\"\n",
    "        )\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def LGB_Beyes(subsample_freq,\n",
    "                    learning_rate,\n",
    "                    feature_fraction,\n",
    "                    max_depth,\n",
    "                    lambda_l1,\n",
    "                    lambda_l2):\n",
    "    params={}\n",
    "    params['subsample_freq']=subsample_freq\n",
    "    params['learning_rate']=learning_rate\n",
    "    params['feature_fraction']=feature_fraction\n",
    "    params['lambda_l1']=lambda_l1\n",
    "    params['lambda_l2']=lambda_l2\n",
    "    params['max_depth']=max_depth\n",
    "    lgb_model = Lgb_Model(reduce_train, ajusted_test, features, categoricals=categoricals,ps=params)\n",
    "    print('kappa: ',lgb_model.score)\n",
    "    return lgb_model.score\n",
    "\n",
    "bounds_LGB = {\n",
    "    'subsample_freq': (1, 3),\n",
    "    'learning_rate': (0.025, 0.4),\n",
    "    'feature_fraction': (0.5, 1),\n",
    "    'lambda_l1': (1, 5),\n",
    "    'lambda_l2': (1, 5),\n",
    "    'max_depth': (15, 17),\n",
    "}\n",
    "\n",
    "params={}\n",
    "\n",
    "if False and os.path.exists('/kaggle/input/data-science-bowl-2019/'):\n",
    "    LGB_BO = BayesianOptimization(LGB_Beyes, bounds_LGB, random_state=1029)\n",
    "    import warnings\n",
    "    init_points = 16\n",
    "    n_iter = 16\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings('ignore')\n",
    "        LGB_BO.maximize(init_points=init_points, n_iter=n_iter, acq='ucb', xi=0.0, alpha=1e-6)\n",
    "        \n",
    "    params = LGB_BO.max['params']\n",
    "    print('\\n', LGB_BO.max['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GroupK CV, optimized QWK\n",
    "# lgb_model = Lgb_Model(reduced_train, reduced_test, features, categoricals=categoricals, ps=params, \n",
    "#                       cv_method='GroupKFold', custom_eval=lgb_reg_qwk)\n",
    "\n",
    "# GroupK CV, weighted rmse\n",
    "# weight = (1 / (reduced_train.groupby('installation_id')['game_session'].transform('nunique')+1)).values\n",
    "weight = (1 / (reduced_train.groupby('installation_id')['game_session'].transform('cumcount')+1)).values\n",
    "lgb_model = Lgb_Model(reduced_train, reduced_test, features, categoricals=categoricals, ps=params, \n",
    "                      cv_method='GroupKFold', custom_eval=lgb_weighted_rmse, weight=weight)\n",
    "\n",
    "# lgb_model = Lgb_Model(reduced_train, reduced_test, features, categoricals=categoricals, ps=params,\n",
    "#                       custom_eval=lgb_reg_qwk)\n",
    "# lgb_model = Lgb_Model(reduced_train, reduced_test, features, categoricals=categoricals, ps=params, custom_eval=lgb_reg_qwk, weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model.plot_importance(lgb_model.models, max_num_features=100, figsize=(12, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = lgb_model.y_pred\n",
    "trian_pred = lgb_model.oof_pred\n",
    "\n",
    "optR = OptimizedRounder(num_class=4)\n",
    "optR.fit(trian_pred, reduced_train['accuracy_group'])\n",
    "opt_preds = optR.predict(trian_pred)\n",
    "\n",
    "sub_preds = optR.predict(final_pred)\n",
    "\n",
    "print(final_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_score = np.sqrt(mean_squared_error(reduced_train['accuracy_group'], lgb_model.oof_pred))\n",
    "print(f'RMSE: {rmse_score}\\n')\n",
    "\n",
    "off_score = qwk3(reduced_train['accuracy_group'], opt_preds)\n",
    "print(f'OOF: {off_score}\\n')\n",
    "\n",
    "print(f'coefficients: {optR.coefficients()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_with_truncated_data(y_pred, y_true, groups, n_trials=10):\n",
    "    eval_result = {}\n",
    "    trials = []\n",
    "    gp_idx_df = pd.DataFrame({\"groups\": groups, \"index\": np.arange(len(y_pred))})\n",
    "    \n",
    "    dice_results = []\n",
    "    for _, df in gp_idx_df.groupby(\"groups\"):\n",
    "        dice_result = np.random.choice(df[\"index\"], size=n_trials)\n",
    "        dice_results.append(dice_result)\n",
    "\n",
    "    idx_choice = np.vstack(dice_results)\n",
    "    for i in range(n_trials):\n",
    "        y_pred_choice = y_pred[idx_choice[:, i]]\n",
    "        y_true_choice = y_true[idx_choice[:, i]]\n",
    "        trials.append(qwk3(y_true_choice, y_pred_choice))\n",
    "\n",
    "    mean_score = np.mean(trials)\n",
    "    median_score = np.median(trials)\n",
    "    std = np.std(trials)\n",
    "    eval_result[\"mean\"] = mean_score\n",
    "    eval_result[\"median\"] = median_score\n",
    "    eval_result[\"all_trials\"] = trials\n",
    "    eval_result[\"0.95lower_bound\"] = mean_score - 2 * std\n",
    "    eval_result[\"0.95upper_bound\"] = mean_score + 2 * std\n",
    "    eval_result[\"std\"] = std\n",
    "    return eval_result\n",
    "\n",
    "truncated_score = eval_with_truncated_data(opt_preds, reduced_train['accuracy_group'], reduced_train['installation_id'])\n",
    "\n",
    "print(f\"Truncated OOF QWK: {truncated_score['mean']:.4f}\")\n",
    "print(f\"Truncated OOF QWK median: {truncated_score['median']:.4f}\")\n",
    "print(f\"Truncated OOF QWK 0.95 upper: {truncated_score['0.95upper_bound']:.4f}\")\n",
    "print(f\"Truncated OOF QWK 0.95 lower: {truncated_score['0.95lower_bound']:.4f}\")\n",
    "print(f\"Truncated OOF QWK std: {truncated_score['std']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'OOF: {off_score}')\n",
    "print(f\"Truncated OOF QWK: {truncated_score['mean']:.4f}\")\n",
    "\n",
    "def plot_cm(y_true, y_pred, figsize=(8, 8)):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=np.unique(y_true))\n",
    "    cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
    "    cm_perc = cm / cm_sum.astype(float) * 100\n",
    "    annot = np.empty_like(cm).astype(str)\n",
    "    nrows, ncols = cm.shape\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            c = cm[i, j]\n",
    "            p = cm_perc[i, j]\n",
    "            if i == j:\n",
    "                s = cm_sum[i]\n",
    "                annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n",
    "            elif c == 0:\n",
    "                annot[i, j] = ''\n",
    "            else:\n",
    "                annot[i, j] = '%.1f%%\\n%d' % (p, c)\n",
    "    cm = pd.DataFrame(cm, index=np.unique(y_true), columns=np.unique(y_true))\n",
    "    cm.index.name = 'Actual'\n",
    "    cm.columns.name = 'Predicted'\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    sns.heatmap(cm, cmap=plt.cm.Blues, square=True, annot=annot, fmt='', ax=ax)\n",
    "\n",
    "\n",
    "plt.title('Accuracy Group Distribution')\n",
    "reduced_train['accuracy_group'].hist(align='left', rwidth=0.4, normed=True, color='tab:blue', label='actual')\n",
    "pd.Series(opt_preds).hist(align='mid', rwidth=0.4, normed=True, color='tab:cyan', label='predict')\n",
    "pd.Series(sub_preds).hist(align='right', rwidth=0.4, normed=True, color='tab:orange', label='submission')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plot_cm(reduced_train['accuracy_group'], opt_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['accuracy_group'] = sub_preds\n",
    "display(sample_submission['accuracy_group'].value_counts(normalize=True).sort_index())\n",
    "\n",
    "if os.path.exists('/kaggle/input/data-science-bowl-2019/'):\n",
    "    sample_submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "16c15db6f6254e71acc9b95016283200": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "1a3c05de029b4175a26225cbb194f3c8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "27bb6561b1544eebb9cfd7b4f2c7ca0f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6ff00c5524a74e36834f9c394bc9e550",
       "placeholder": "​",
       "style": "IPY_MODEL_3ec4aa5ca6994e06ad4994e29b3be796",
       "value": " 1000/1000 [02:25&lt;00:00,  6.88it/s]"
      }
     },
     "3140aa7101094a2ab498c33126c2e160": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3ec4aa5ca6994e06ad4994e29b3be796": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "55919e11c6c04441a14c348b46187ba9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "6b6f58ab735e40c88d804d33da718fa7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6d42bbb6ca114fe2bfb7c599f8878be3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3140aa7101094a2ab498c33126c2e160",
       "max": 17000,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_55919e11c6c04441a14c348b46187ba9",
       "value": 17000
      }
     },
     "6ff00c5524a74e36834f9c394bc9e550": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8453bb3bc2a34d90a51c787224debe35": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e9afc751d1994c48af0764907308ea75",
        "IPY_MODEL_27bb6561b1544eebb9cfd7b4f2c7ca0f"
       ],
       "layout": "IPY_MODEL_1a3c05de029b4175a26225cbb194f3c8"
      }
     },
     "9446846a28ef4d8db9392f1fcf24d774": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6d42bbb6ca114fe2bfb7c599f8878be3",
        "IPY_MODEL_ed849081b5bf4605a594778a2edbf548"
       ],
       "layout": "IPY_MODEL_dca885bb19a8492d802df0bd42a413e1"
      }
     },
     "be9af6bee8044790889a5cfcedf52367": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c5f62c223b6a410ebde8de79c163d640": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "dca885bb19a8492d802df0bd42a413e1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e9afc751d1994c48af0764907308ea75": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_be9af6bee8044790889a5cfcedf52367",
       "max": 1000,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c5f62c223b6a410ebde8de79c163d640",
       "value": 1000
      }
     },
     "ed849081b5bf4605a594778a2edbf548": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6b6f58ab735e40c88d804d33da718fa7",
       "placeholder": "​",
       "style": "IPY_MODEL_16c15db6f6254e71acc9b95016283200",
       "value": " 17000/17000 [10:34&lt;00:00, 26.79it/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
