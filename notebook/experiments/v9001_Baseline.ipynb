{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rui/.local/share/virtualenvs/data_science_bowl-_c7OiX6v/lib/python3.8/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/rui/.local/share/virtualenvs/data_science_bowl-_c7OiX6v/lib/python3.8/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_selection.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import re\n",
    "import json\n",
    "import copy\n",
    "import time\n",
    "import eli5\n",
    "import datetime\n",
    "from numba import jit\n",
    "\n",
    "from IPython.display import HTML\n",
    "import altair as alt\n",
    "from category_encoders.ordinal import OrdinalEncoder\n",
    "from typing import List, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from xgboost import plot_importance\n",
    "\n",
    "import catboost as cat\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "import shap\n",
    "\n",
    "from itertools import product\n",
    "from functools import partial\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import NuSVR, SVR\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import cohen_kappa_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "from time import time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('max_rows', 500)\n",
    "pd.options.display.precision = 15\n",
    "np.random.seed(42)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "source": [
    "# Objective\n",
    "\n",
    "- 特徴量の追加を行う。\n",
    "- 精度の上昇有無は、LGBMのみの予測スコアと比較することで行う。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "lightGBM, catboostのアンサンブル。\n",
    "\n",
    "last_sessin_typeから手動でパラメータの補正を行った。\n",
    "\n",
    "\n",
    "- CV score with added features\n",
    "    - baseline\n",
    "        - oof: 0.6439205652460508\n",
    "        - Equal data: mean 0.581, std 0.021\n",
    "    - group k fold\n",
    "        - oof: 0.6318546575158306\n",
    "        - Equal data: mean 0.564, std 0.023\n",
    "    - emsanble\n",
    "        - off: 0.6454824368456962\n",
    "        - Equal data: mean 0.587, std 0.026"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    if os.path.exists('/kaggle/input/data-science-bowl-2019/'):\n",
    "        data_dir_path = '/kaggle/input/data-science-bowl-2019/'\n",
    "    else:\n",
    "        data_dir_path = '../../data/raw/'\n",
    "        \n",
    "    \n",
    "    print('Reading train.csv file....')\n",
    "    train = pd.read_csv(data_dir_path+'train.csv')\n",
    "    print('Training.csv file have {} rows and {} columns'.format(train.shape[0], train.shape[1]))\n",
    "\n",
    "    print('Reading test.csv file....')\n",
    "    test = pd.read_csv(data_dir_path+'test.csv')\n",
    "    print('Test.csv file have {} rows and {} columns'.format(test.shape[0], test.shape[1]))\n",
    "\n",
    "    print('Reading train_labels.csv file....')\n",
    "    train_labels = pd.read_csv(data_dir_path+'train_labels.csv')\n",
    "    print('Train_labels.csv file have {} rows and {} columns'.format(train_labels.shape[0], train_labels.shape[1]))\n",
    "\n",
    "    print('Reading specs.csv file....')\n",
    "    specs = pd.read_csv(data_dir_path+'specs.csv')\n",
    "    print('Specs.csv file have {} rows and {} columns'.format(specs.shape[0], specs.shape[1]))\n",
    "\n",
    "    print('Reading sample_submission.csv file....')\n",
    "    sample_submission = pd.read_csv(data_dir_path+'sample_submission.csv')\n",
    "    print('Sample_submission.csv file have {} rows and {} columns'.format(sample_submission.shape[0], sample_submission.shape[1]))\n",
    "    return train, test, train_labels, specs, sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train.csv file....\n",
      "Training.csv file have 11341042 rows and 11 columns\n",
      "Reading test.csv file....\n",
      "Test.csv file have 1156414 rows and 11 columns\n",
      "Reading train_labels.csv file....\n",
      "Train_labels.csv file have 17690 rows and 7 columns\n",
      "Reading specs.csv file....\n",
      "Specs.csv file have 386 rows and 3 columns\n",
      "Reading sample_submission.csv file....\n",
      "Sample_submission.csv file have 1000 rows and 2 columns\n"
     ]
    }
   ],
   "source": [
    "raw_train, raw_test, train_labels, specs, sample_submission = read_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_title(raw_train, raw_test, train_labels):\n",
    "    train = raw_train.copy()\n",
    "    test = raw_test.copy()\n",
    "    # encode title\n",
    "    train['title_event_code'] = sorted(list(map(lambda x, y: str(x) + '_' + str(y), train['title'], train['event_code'])))\n",
    "    test['title_event_code'] = sorted(list(map(lambda x, y: str(x) + '_' + str(y), test['title'], test['event_code'])))\n",
    "    all_title_event_code = sorted(list(set(train[\"title_event_code\"].unique()).union(test[\"title_event_code\"].unique())))\n",
    "    # make a list with all the unique 'titles' from the train and test set\n",
    "    list_of_user_activities = sorted(list(set(train['title'].unique()).union(set(test['title'].unique()))))\n",
    "    # make a list with all the unique 'event_code' from the train and test set\n",
    "    list_of_event_code = sorted(list(set(train['event_code'].unique()).union(set(test['event_code'].unique()))))\n",
    "    list_of_event_id = sorted(list(set(train['event_id'].unique()).union(set(test['event_id'].unique()))))\n",
    "    # make a list with all the unique worlds from the train and test set\n",
    "    list_of_worlds = sorted(list(set(train['world'].unique()).union(set(test['world'].unique()))))\n",
    "    list_of_types = sorted(list(set(train['type'].unique()).union(set(test['type'].unique()))))\n",
    "    list_of_game_worlds = sorted(list(set(raw_train.loc[raw_train['type']=='Game', 'title'].unique()\n",
    "                                  ).union(set(raw_test.loc[raw_test['type']=='Game', 'title'].unique()))))\n",
    "    # create a dictionary numerating the titles\n",
    "    activities_map = dict(zip(list_of_user_activities, np.arange(len(list_of_user_activities))))\n",
    "    types_map = {w: i for i, w in enumerate(sorted(list_of_types))}\n",
    "    activities_labels = dict(zip(np.arange(len(list_of_user_activities)), list_of_user_activities))\n",
    "#     activities_world = dict(zip(list_of_worlds, np.arange(len(list_of_worlds))))\n",
    "    assess_titles = sorted(list(set(train[train['type'] == 'Assessment']['title'].value_counts().index\n",
    "                                   ).union(set(test[test['type'] == 'Assessment']['title'].value_counts().index))))\n",
    "    # replace the text titles with the number titles from the dict\n",
    "    train['title'] = train['title'].map(activities_map)\n",
    "    test['title'] = test['title'].map(activities_map)\n",
    "#     train['world'] = train['world'].map(activities_world)\n",
    "#     test['world'] = test['world'].map(activities_world)\n",
    "    train_labels['title'] = train_labels['title'].map(activities_map)\n",
    "    win_code = dict(zip(activities_map.values(), (4100*np.ones(len(activities_map))).astype('int')))\n",
    "    # then, it set one element, the 'Bird Measurer (Assessment)' as 4110, 10 more than the rest\n",
    "    win_code[activities_map['Bird Measurer (Assessment)']] = 4110\n",
    "    # convert text into datetime\n",
    "    train['timestamp'] = pd.to_datetime(train['timestamp'])\n",
    "    test['timestamp'] = pd.to_datetime(test['timestamp'])\n",
    "    \n",
    "    train['hour'] = train['timestamp'].dt.hour\n",
    "    test['hour'] = test['timestamp'].dt.hour\n",
    "    train['weekday'] = train['timestamp'].dt.weekday\n",
    "    test['weekday'] = test['timestamp'].dt.weekday\n",
    "    \n",
    "    return train, test, train_labels, win_code, list_of_user_activities, list_of_event_code, activities_labels, \\\n",
    "        assess_titles, list_of_event_id, all_title_event_code, list_of_worlds, list_of_game_worlds, types_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_time = {\n",
    "    'Welcome to Lost Lagoon!':19,'Tree Top City - Level 1':17,'Ordering Spheres':61, 'Costume Box':61,\n",
    "    '12 Monkeys':109,'Tree Top City - Level 2':25, 'Pirate\\'s Tale':80, 'Treasure Map':156,'Tree Top City - Level 3':26,\n",
    "    'Rulers':126, 'Magma Peak - Level 1':20, 'Slop Problem':60, 'Magma Peak - Level 2':22, 'Crystal Caves - Level 1':18,\n",
    "    'Balancing Act':72, 'Lifting Heavy Things':118,'Crystal Caves - Level 2':24, 'Honey Cake':142, 'Crystal Caves - Level 3':19,\n",
    "    'Heavy, Heavier, Heaviest':61\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_timestamp_second(pre_ts, ts):\n",
    "    return (ts - pre_ts).total_seconds() if pre_ts is not None else -1\n",
    "\n",
    "def parse_game_session(session):\n",
    "    game_title = session['title'].iloc[-1]\n",
    "    game_world = session['world'].iloc[-1]\n",
    "    game_num_correct = session['event_data'].str.contains('\"correct\":true').astype(int).sum()\n",
    "    game_num_incorrect = session['event_data'].str.contains('\"correct\":false').astype(int).sum()\n",
    "    game_num_trial = game_num_correct + game_num_incorrect\n",
    "    game_accuracy = game_num_correct/game_num_trial if game_num_trial>0 else -1\n",
    "    game_num_event_count = session['event_count'].iloc[-1]\n",
    "    game_session_mean = session['game_time'].diff().mean()\n",
    "    game_session_std = session['game_time'].diff().std()\n",
    "    game_round = session[session['event_data'].str.contains('round')]['event_data'].str.extract('.\"round\":(\\w).').max()[0]\n",
    "    game_sum_misses = session[session['event_data'].str.contains('round')]['event_data'].str.extract('.\"misses\":(\\w).').sum()\n",
    "    game_sum_misses = game_sum_misses[0] if len(game_sum_misses)>0 else -1\n",
    "    \n",
    "    return game_title, game_world, game_num_correct, game_num_incorrect, game_num_trial, \\\n",
    "            game_accuracy, game_num_event_count, game_session_mean, game_session_std, \\\n",
    "            game_round, game_sum_misses\n",
    "\n",
    "# this is the function that convert the raw data into processed features\n",
    "def get_data(user_sample, test_set=False):\n",
    "    '''\n",
    "    The user_sample is a DataFrame from train or test where the only one \n",
    "    installation_id is filtered\n",
    "    And the test_set parameter is related with the labels processing, that is only requered\n",
    "    if test_set=False\n",
    "    '''\n",
    "    # 学習データとなるリスト（出力値）\n",
    "    all_assessments = [] \n",
    "    \n",
    "    # installation_idごとの特徴量\n",
    "    # Constants and parameters declaration\n",
    "    last_activity = 0\n",
    "    # typeごとの回数\n",
    "    user_activities_count = {'Clip':0, 'Activity': 0, 'Assessment': 0, 'Game':0}\n",
    "    \n",
    "    # new features: time spent in each activity\n",
    "    # 最後のセッションの時間\n",
    "    last_session_time_sec = 0\n",
    "    last_sessin_world = None\n",
    "    last_sessin_type = None\n",
    "    last_session_datetime = None\n",
    "    seconds_from_last_session = None\n",
    "    last_session_type_duration = {f'last_session_{t}_session': 0 for t in types_map.keys()}\n",
    "    last_session_world_duration = {f'last_session_{w}_session': 0 for w in list_of_worlds}\n",
    "    last_session_title_duration = {f'last_session_{w}_session': 0 for w in activities_labels.values()}\n",
    "    each_type_last_timestamp = {t: None for t in types_map.keys()}\n",
    "    each_world_last_timestamp = {world: None for world in list_of_worlds}\n",
    "    each_title_last_timestamp = {title: None for title in activities_labels.values()}\n",
    "    # 直前のGame_Sessionから得られる特徴量\n",
    "    last_game_title = None\n",
    "    last_game_world = None\n",
    "    last_game_num_correct = 0\n",
    "    last_game_num_incorrect = 0\n",
    "    last_game_num_trial = 0\n",
    "    last_game_accuracy = 0\n",
    "    last_game_num_event_count = 0\n",
    "    last_game_session_mean = 0\n",
    "    last_game_session_std = 0\n",
    "    last_game_round = 0\n",
    "    mean_game_round = 0.0\n",
    "    accumulated_game_accuracy = 0.0\n",
    "    accumulated_game_sum_misses = 0\n",
    "    accumulated_each_world_game_accuracy: Dict[str, float] = {f'accumulated_game_accuracy_of_{world}': 0.0 for world in list_of_worlds}\n",
    "    # Assessmentから得られる特徴量\n",
    "    accuracy_groups = {0:0, 1:0, 2:0, 3:0} # accuracy_groupの回数\n",
    "    accumulated_accuracy_group = 0 # 累積のaccuracy_group。最後にassessmenに挑戦した回数（counter）で割っている。\n",
    "    accumulated_accuracy = 0 # 累積のaccuracy。単純に正答率を足し合わせている。\n",
    "    accumulated_correct_attempts = 0 # 累積のcorrect_attempts\n",
    "    accumulated_uncorrect_attempts = 0 # 累積のuncorrect_attempts\n",
    "    accumulated_actions = 0 # 全てのセッションにおけるイベント回数\n",
    "    counter = 0 # Assessmentに挑戦した回数\n",
    "    time_first_activity = float(user_sample['timestamp'].values[0])\n",
    "    accumulated_each_world_accuracy: Dict[str, float] = {f'accumulated_accuracy_of_{world}': 0.0 for world in list_of_worlds}\n",
    "    # セッション時間の特徴量\n",
    "    # each session type\n",
    "    Assessment_durations = []\n",
    "    clip_durations = [] # clipだけのセッション時間\n",
    "    Activity_durations = [] # Activityだけのセッション時間\n",
    "    Game_durations = [] # Gameだけのセッション時間\n",
    "    world_durations: Dict[str, list] = {world: [] for world in list_of_worlds}\n",
    "    \n",
    "    last_accuracy_title = {f'acc_{title}' : -1 for title in assess_titles} # titleごとの最後の正答率\n",
    "    last_game_accuracy_title = {f'game_acc_{title}': -1 for title in list_of_game_worlds}\n",
    "    event_code_count: Dict[str, int] = {ev: 0 for ev in list_of_event_code}\n",
    "    game_event_code_count: Dict[str, int] = { str(ev) + '_g': 0 for ev in list_of_event_code}\n",
    "    Activity_event_code_count: Dict[str, int] = {str(ev) + '_A': 0 for ev in list_of_event_code}    \n",
    "    event_id_count: Dict[str, int] = {eve: 0 for eve in list_of_event_id}\n",
    "    Activity_sum_event_count = 0\n",
    "    game_sum_event_count = 0\n",
    "#     game_event_id_count: Dict[str, int] = {eve+'_g': 0 for eve in list_of_event_id}\n",
    "#     Activity_event_id_count: Dict[str, int] = {eve+'_A': 0 for eve in list_of_event_id}\n",
    "#     Accessment_event_id_count: Dict[str, int] = {eve+'_ac': 0 for eve in list_of_event_id}\n",
    "    world_count: Dict[str, int] = {world: 0 for world in list_of_worlds}\n",
    "    title_count: Dict[str, int] = {eve: 0 for eve in activities_labels.values()} \n",
    "    title_event_code_count: Dict[str, int] = {t_eve: 0 for t_eve in all_title_event_code}\n",
    "    \n",
    "    # End Feature\n",
    "    \n",
    "    # itarates through each session of one instalation_id\n",
    "    for session_cnt, (session_id, session) in enumerate(user_sample.groupby('game_session', sort=False)):\n",
    "        # i = game_session_id\n",
    "        # session is a DataFrame that contain only one game_session\n",
    "        \n",
    "        # get some sessions information\n",
    "        session_type = session['type'].iloc[0]\n",
    "        session_world = session['world'].iloc[0]\n",
    "        session_title = session['title'].iloc[0]\n",
    "#         session_game_time = session['game_time'].iloc[-1]\n",
    "        session_game_time_sec = (session.iloc[-1, 2] - session.iloc[0, 2]).seconds\n",
    "        session_title_text = activities_labels[session_title]\n",
    "        \n",
    "        if session_type == 'Clip':\n",
    "            clip_durations.append((clip_time[activities_labels[session_title]]))\n",
    "        \n",
    "        if session_type == 'Activity':\n",
    "            Activity_sum_event_count = Activity_sum_event_count + session['event_count'].iloc[-1]\n",
    "            Activity_durations.append(session_game_time_sec)\n",
    "            def update_counters(counter: dict, col: str):\n",
    "                num_of_session_count = Counter(session[col])\n",
    "                for k in num_of_session_count.keys():\n",
    "                    x = str(k) + '_A'\n",
    "                    if col == 'title':\n",
    "                        x = activities_labels[k]\n",
    "                    counter[x] += num_of_session_count[k]\n",
    "                return counter\n",
    "            Activity_event_code_count = update_counters(Activity_event_code_count, \"event_code\")\n",
    "#             def update_counters_id(counter: dict, col: str):\n",
    "#                 num_of_session_count = Counter(session[col])\n",
    "#                 for k in num_of_session_count.keys():\n",
    "#                     x = k + '_g'\n",
    "#                     if col == 'title':\n",
    "#                         x = activities_labels[k]\n",
    "#                     counter[x] += num_of_session_count[k]\n",
    "#                 return counter\n",
    "#             Activity_event_id_count = update_counters(Activity_event_id_count, \"event_id\")\n",
    "        \n",
    "        if session_type == 'Game':\n",
    "            # Gameセッションデータを解析\n",
    "            game_title, game_world, game_num_correct, game_num_incorrect, game_num_trial, \\\n",
    "                game_accuracy, game_num_event_count, game_session_mean, game_session_std, \\\n",
    "                game_round, game_sum_misses = parse_game_session(session)\n",
    "            \n",
    "            last_game_title = game_title\n",
    "            last_game_world = game_world\n",
    "            last_game_num_correct = game_num_correct\n",
    "            last_game_num_incorrect = game_num_incorrect\n",
    "            last_game_num_trial = game_num_trial\n",
    "            last_game_accuracy = game_accuracy\n",
    "            last_game_num_event_count = game_num_event_count\n",
    "            last_game_session_mean = game_session_mean\n",
    "            last_game_session_std = game_session_std\n",
    "            last_game_round = game_round\n",
    "            mean_game_round = (mean_game_round+game_round) / 2 if mean_game_round!=0.0 else game_round\n",
    "            accumulated_game_accuracy = game_accuracy\n",
    "            accumulated_game_sum_misses = (accumulated_game_sum_misses+game_sum_misses) / (session_cnt+1)\n",
    "            last_game_accuracy_title[f'game_acc_{game_title}'] = game_accuracy\n",
    "            \n",
    "            _temp_acc_game_accuracy = accumulated_each_world_game_accuracy[f'accumulated_game_accuracy_of_{game_world}']\n",
    "            _temp_acc_game_accuracy = (_temp_acc_game_accuracy+game_accuracy) / 2 if _temp_acc_game_accuracy!=0.0 else game_accuracy\n",
    "            accumulated_each_world_game_accuracy[f'accumulated_game_accuracy_of_{game_world}'] = _temp_acc_game_accuracy\n",
    "            \n",
    "            game_sum_event_count = game_sum_event_count + session['event_count'].iloc[-1]\n",
    "            Game_durations.append(session_game_time_sec)\n",
    "            def update_counters(counter: dict, col: str):\n",
    "                num_of_session_count = Counter(session[col])\n",
    "                for k in num_of_session_count.keys():\n",
    "                    x = str(k) + '_g'\n",
    "                    if col == 'title':\n",
    "                        x = activities_labels[k]\n",
    "                    counter[x] += num_of_session_count[k]\n",
    "                return counter\n",
    "            game_event_code_count = update_counters(game_event_code_count, \"event_code\")\n",
    "#             def update_counters_id(counter: dict, col: str):\n",
    "#                 num_of_session_count = Counter(session[col])\n",
    "#                 for k in num_of_session_count.keys():\n",
    "#                     x = k + '_g'\n",
    "#                     if col == 'title':\n",
    "#                         x = activities_labels[k]\n",
    "#                     counter[x] += num_of_session_count[k]\n",
    "#                 return counter\n",
    "#             game_event_id_count = update_counters(game_event_id_count, \"event_id\")\n",
    "\n",
    "        # for each assessment, and only this kind off session, the features below are processed\n",
    "        # and a register are generated\n",
    "        if (session_type == 'Assessment') & (test_set or len(session)>1):\n",
    "            # search for event_code 4100, that represents the assessments trial\n",
    "            all_attempts = session.query(f'event_code == {win_code[session_title]}')\n",
    "            # then, check the numbers of wins and the number of losses\n",
    "            true_attempts = all_attempts['event_data'].str.contains('true').sum()\n",
    "            false_attempts = all_attempts['event_data'].str.contains('false').sum()\n",
    "            # copy a dict to use as feature template, it's initialized with some itens: \n",
    "            # {'Clip':0, 'Activity': 0, 'Assessment': 0, 'Game':0}\n",
    "            features = user_activities_count.copy()\n",
    "            features.update(last_accuracy_title.copy())\n",
    "            features.update(event_code_count.copy())\n",
    "            features.update(event_id_count.copy())\n",
    "            \n",
    "            features.update(game_event_code_count.copy())\n",
    "#             features.update(game_event_id_count.copy())\n",
    "            features.update(Activity_event_code_count.copy())\n",
    "#             features.update(Activity_event_id_count.copy())\n",
    "#             features.update(Accessment_event_id_count.copy())\n",
    "            \n",
    "            features.update(world_count.copy())\n",
    "            features.update(title_count.copy())\n",
    "            features.update(title_event_code_count.copy())\n",
    "            features['installation_session_count'] = session_cnt\n",
    "            features['hour'] = session['hour'].iloc[-1]\n",
    "            features['weekday'] = session['weekday'].iloc[-1]\n",
    "            variety_features = [('var_event_code', event_code_count),\n",
    "                              ('var_event_id', event_id_count),\n",
    "                               ('var_title', title_count),\n",
    "                               ('var_title_event_code', title_event_code_count)]\n",
    "            \n",
    "            for name, dict_counts in variety_features:\n",
    "                arr = np.array(list(dict_counts.values()))\n",
    "                features[name] = np.count_nonzero(arr)\n",
    "                 \n",
    "            # get installation_id for aggregated features\n",
    "            features['installation_id'] = session['installation_id'].iloc[-1]\n",
    "            # add title as feature, remembering that title represents the name of the game\n",
    "            features['session_title'] = session['title'].iloc[0]\n",
    "            features['num_of_post_words'] = sum([v>0 for v in world_count.values()])\n",
    "            # the 4 lines below add the feature of the history of the trials of this player\n",
    "            # this is based on the all time attempts so far, at the moment of this assessment\n",
    "            features['accumulated_correct_attempts'] = accumulated_correct_attempts\n",
    "            features['accumulated_uncorrect_attempts'] = accumulated_uncorrect_attempts\n",
    "            features['game_sum_event_count'] = game_sum_event_count\n",
    "            features['Activity_sum_event_count'] = game_sum_event_count\n",
    "            features.update(accumulated_each_world_accuracy.copy())\n",
    "            accumulated_correct_attempts += true_attempts \n",
    "            accumulated_uncorrect_attempts += false_attempts\n",
    "            # the time spent in the app so far\n",
    "            features['Assessment_duration_mean'] = np.mean(Assessment_durations) if len(Assessment_durations)!=0 else 0.0\n",
    "            features['Assessment_duration_std'] = np.std(Assessment_durations) if len(Assessment_durations)!=0 else 0.0\n",
    "            features['Clip_duration_mean'] = np.mean(clip_durations) if len(clip_durations)!=0 else 0.0\n",
    "            features['Clip_duration_std'] = np.std(clip_durations) if len(clip_durations)!=0 else 0.0\n",
    "            features['Activity_duration_mean'] = np.mean(Activity_durations) if len(Activity_durations)!=0 else 0.0\n",
    "            features['Activity_duration_std'] = np.std(Activity_durations) if len(Activity_durations)!=0 else 0.0\n",
    "            features['Game_duration_mean'] = np.mean(Game_durations) if len(Game_durations)!=0 else 0.0\n",
    "            features['Game_duration_std'] = np.std(Game_durations) if len(Game_durations)!=0 else 0.0\n",
    "            \n",
    "            # parse each world durations\n",
    "            for key, val in world_durations.items():\n",
    "#                 features[f'{key}_duration_sum'] = np.sum(val) if len(val)!=0 else 0.0\n",
    "                features[f'{key}_duration_mean'] = np.mean(val) if len(val)!=0 else 0.0\n",
    "                features[f'{key}_duration_std'] = np.std(val) if len(val)!=0 else 0.0\n",
    "                \n",
    "            # 直前のGame Sessionの特徴量を更新\n",
    "#             features.update(last_game_accuracy_title)\n",
    "            features.update(accumulated_each_world_game_accuracy)\n",
    "            features.update({\n",
    "#                 'last_game_title': last_game_title,\n",
    "#                 'last_game_world': last_game_world,\n",
    "                'last_game_num_correct': last_game_num_correct,\n",
    "                'last_game_num_incorrect': last_game_num_incorrect,\n",
    "                'last_game_num_trial': last_game_num_trial,\n",
    "                'last_game_accuracy': last_game_accuracy,\n",
    "                'last_game_num_event_count': last_game_num_event_count,\n",
    "                'last_game_session_mean': last_game_session_mean,\n",
    "                'last_game_session_std': last_game_session_std,\n",
    "                'last_game_round': last_game_round,\n",
    "                'mean_game_round': mean_game_round,\n",
    "                'accumulated_game_accuracy': accumulated_game_accuracy,\n",
    "                'accumulated_game_sum_misses': accumulated_game_sum_misses,\n",
    "                'multi_last_round_game_accuracy': last_game_accuracy*last_game_round\n",
    "            })\n",
    "                \n",
    "            Assessment_durations.append(session_game_time_sec)\n",
    "            # the accurace is the all time wins divided by the all time attempts\n",
    "            features['accumulated_accuracy'] = accumulated_accuracy/counter if counter > 0 else 0\n",
    "            accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n",
    "            accumulated_accuracy += accuracy\n",
    "            accumulated_each_world_accuracy[f'accumulated_accuracy_of_{session_world}'] += accuracy\n",
    "            last_accuracy_title['acc_' + session_title_text] = accuracy\n",
    "            # a feature of the current accuracy categorized\n",
    "            # it is a counter of how many times this player was in each accuracy group\n",
    "            if accuracy == 0:\n",
    "                features['accuracy_group'] = 0\n",
    "            elif accuracy == 1:\n",
    "                features['accuracy_group'] = 3\n",
    "            elif accuracy == 0.5:\n",
    "                features['accuracy_group'] = 2\n",
    "            else:\n",
    "                features['accuracy_group'] = 1\n",
    "            features.update(accuracy_groups)\n",
    "            accuracy_groups[features['accuracy_group']] += 1\n",
    "            # mean of the all accuracy groups of this player\n",
    "            features['accumulated_accuracy_group'] = accumulated_accuracy_group/counter if counter > 0 else 0\n",
    "            accumulated_accuracy_group += features['accuracy_group']\n",
    "            # how many actions the player has done so far, it is initialized as 0 and updated some lines below\n",
    "            features['accumulated_actions'] = accumulated_actions\n",
    "            # last session data\n",
    "            features.update(last_session_type_duration)\n",
    "            features.update(last_session_world_duration)\n",
    "            features.update(last_session_title_duration)\n",
    "            features['last_session_time_sec'] = last_session_time_sec\n",
    "            features['last_sessin_world'] = last_sessin_world\n",
    "            features['last_sessin_type'] = last_sessin_type\n",
    "            features['seconds_from_last_session'] = diff_timestamp_second(last_session_datetime, session.iloc[-1]['timestamp'])\n",
    "            for key, val in each_type_last_timestamp.items():\n",
    "                features[f'duration_from_last_{key}_session'] = diff_timestamp_second(val, session.iloc[-1]['timestamp'])\n",
    "            for key, val in each_world_last_timestamp.items():\n",
    "                features[f'duration_from_last_{key}_session'] = diff_timestamp_second(val, session.iloc[-1]['timestamp'])\n",
    "            for key, val in each_title_last_timestamp.items():\n",
    "                features[f'duration_from_last_{key}_session'] = diff_timestamp_second(val, session.iloc[-1]['timestamp'])\n",
    "                \n",
    "            \n",
    "            # there are some conditions to allow this features to be inserted in the datasets\n",
    "            # if it's a test set, all sessions belong to the final dataset\n",
    "            # it it's a train, needs to be passed throught this clausule: session.query(f'event_code == {win_code[session_title]}')\n",
    "            # that means, must exist an event_code 4100 or 4110\n",
    "            if test_set:\n",
    "                all_assessments.append(features)\n",
    "            elif true_attempts+false_attempts > 0:\n",
    "                all_assessments.append(features)  \n",
    "            counter += 1\n",
    "        \n",
    "        # World-related features\n",
    "        world_count[session_world] += 1\n",
    "        world_durations[session_world].append(session_game_time_sec)\n",
    "        # this piece counts how many actions was made in each event_code so far\n",
    "        def update_counters(counter: dict, col: str):\n",
    "                num_of_session_count = Counter(session[col])\n",
    "                for k in num_of_session_count.keys():\n",
    "                    x = k\n",
    "                    if col == 'title':\n",
    "                        x = activities_labels[k]\n",
    "                    counter[x] += num_of_session_count[k]\n",
    "                return counter\n",
    "            \n",
    "        event_code_count = update_counters(event_code_count, \"event_code\")\n",
    "        event_id_count = update_counters(event_id_count, \"event_id\")\n",
    "        title_count = update_counters(title_count, 'title')\n",
    "        title_event_code_count = update_counters(title_event_code_count, 'title_event_code')\n",
    "\n",
    "        # counts how many actions the player has done so far, used in the feature of the same name\n",
    "        accumulated_actions += len(session)\n",
    "        if last_activity != session_type:\n",
    "            user_activities_count[session_type] += 1\n",
    "            last_activitiy = session_type \n",
    "        \n",
    "        last_session_time_sec = session_game_time_sec\n",
    "        last_sessin_world = session_world\n",
    "        last_sessin_type = session_type\n",
    "        last_session_type_duration[f'last_session_{session_type}_session'] = session_game_time_sec\n",
    "        last_session_world_duration[f'last_session_{session_world}_session'] = session_game_time_sec\n",
    "        last_session_title_duration[f'last_session_{session_title}_session'] = session_game_time_sec\n",
    "        \n",
    "        last_session_datetime = session.iloc[-1]['timestamp']\n",
    "        each_type_last_timestamp[session_type] = session.iloc[-1]['timestamp']\n",
    "        each_world_last_timestamp[session_world] = session.iloc[-1]['timestamp']\n",
    "        each_title_last_timestamp[session_title] = session.iloc[-1]['timestamp']\n",
    "                        \n",
    "    # if it't the test_set, only the last assessment must be predicted, the previous are scraped\n",
    "    if test_set:\n",
    "        return all_assessments[-1]\n",
    "    # in the train_set, all assessments goes to the dataset\n",
    "    return all_assessments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_and_test(train, test):\n",
    "    compiled_train = []\n",
    "    compiled_test = []\n",
    "    \n",
    "    for ins_id, user_sample in tqdm(train.groupby('installation_id', sort = False), total = 17000):\n",
    "        compiled_train += get_data(user_sample)\n",
    "    \n",
    "    for ins_id, user_sample in tqdm(test.groupby('installation_id', sort = False), total = 1000):\n",
    "        test_data = get_data(user_sample, test_set = True)\n",
    "        compiled_test.append(test_data)\n",
    "    \n",
    "    reduce_train = pd.DataFrame(compiled_train)\n",
    "    reduce_test = pd.DataFrame(compiled_test)\n",
    "    \n",
    "    # カテゴリカルに関するデータを置換\n",
    "    # last_sessin_world\n",
    "    map_of_worlds = {w: i for i, w in enumerate(sorted(list_of_worlds))}\n",
    "    reduce_train['last_sessin_world'] = reduce_train['last_sessin_world'].map(map_of_worlds).fillna(-1).astype(int)\n",
    "    reduce_test['last_sessin_world'] = reduce_test['last_sessin_world'].map(map_of_worlds).fillna(-1).astype(int)\n",
    "    # last_sessin_world\n",
    "    reduce_train['last_sessin_type'] = reduce_train['last_sessin_type'].map(types_map).fillna(-1).astype(int)\n",
    "    reduce_test['last_sessin_type'] = reduce_test['last_sessin_type'].map(types_map).fillna(-1).astype(int)\n",
    "    # last_game_world\n",
    "#     reduce_train['last_game_world'] = reduce_train['last_game_world'].map(map_of_worlds).fillna(-1).astype(int)\n",
    "#     reduce_test['last_game_world'] = reduce_test['last_game_world'].map(map_of_worlds).fillna(-1).astype(int)\n",
    "\n",
    "    categoricals = ['session_title', 'last_sessin_world', 'last_sessin_type']\n",
    "    return reduce_train, reduce_test, categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def agg_stats(train, test, agg_target, agg_cols, agg_funcs=['mean', 'std', 'min', 'max']):\n",
    "#     \"\"\"MEMO:\n",
    "#     - agg_target: 集約される特徴量\n",
    "#     - agg_cols: 集約する特徴量\n",
    "#     - agg_funcs: 集約関数\n",
    "#     \"\"\"\n",
    "#     all_df = pd.concat([train, test], axis=0, sort=False)\n",
    "#     dst_df = pd.DataFrame()\n",
    "#     for agg_col in agg_cols:\n",
    "#         for agg_func in agg_funcs:\n",
    "#             col_name = f'{agg_target}_{agg_func.upper()}_by_{agg_col}'\n",
    "#             if agg_func == 'diff':\n",
    "#                 dst_df[col_name] = all_df[agg_target] - all_df.groupby([agg_col])[agg_target].transform('mean')\n",
    "#             elif agg_func == 'division':\n",
    "#                 dst_df[col_name] = all_df[agg_target] / all_df.groupby([agg_col])[agg_target].transform('mean')\n",
    "#             else:\n",
    "#                 dst_df[col_name] = all_df.groupby([agg_col])[agg_target].transform(agg_func)\n",
    "\n",
    "#     dst_train = dst_df[0:train.shape[0]]\n",
    "#     dst_test = dst_df[-test.shape[0]:]\n",
    "#     return dst_train, dst_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0777893faf4c447ba816e604a2894609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get usefull dict with maping encode\n",
    "train, test, train_labels, win_code, list_of_user_activities, list_of_event_code, \\\n",
    "    activities_labels, assess_titles, list_of_event_id, all_title_event_code, list_of_worlds,\\\n",
    "    list_of_game_worlds, types_map = encode_title(raw_train, raw_test, train_labels)\n",
    "\n",
    "# tranform function to get the train and test set\n",
    "reduce_train, reduce_test, categoricals = get_train_and_test(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stract_hists(feature, train=reduce_train, test=reduce_test, adjust=False, plot=False):\n",
    "    n_bins = 10\n",
    "    train_data = train[feature]\n",
    "    test_data = test[feature]\n",
    "    if adjust:\n",
    "        test_data *= train_data.mean() / test_data.mean()\n",
    "    perc_90 = np.percentile(train_data, 95)\n",
    "    train_data = np.clip(train_data, 0, perc_90)\n",
    "    test_data = np.clip(test_data, 0, perc_90)\n",
    "    train_hist = np.histogram(train_data, bins=n_bins)[0] / len(train_data)\n",
    "    test_hist = np.histogram(test_data, bins=n_bins)[0] / len(test_data)\n",
    "    msre = mean_squared_error(train_hist, test_hist)\n",
    "    if plot:\n",
    "        print(msre)\n",
    "        plt.bar(range(n_bins), train_hist, color='blue', alpha=0.5)\n",
    "        plt.bar(range(n_bins), test_hist, color='red', alpha=0.5)\n",
    "        plt.show()\n",
    "    return msre\n",
    "stract_hists('last_game_num_correct', adjust=False, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column名をLGBMが扱える形に変更\n",
    "reduce_train.columns = [\"\".join(c if c.isalnum() else \"_\" for c in str(x)) for x in reduce_train.columns]\n",
    "reduce_test.columns = [\"\".join(c if c.isalnum() else \"_\" for c in str(x)) for x in reduce_test.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call feature engineering function\n",
    "features = reduce_train.loc[(reduce_train.sum(axis=1) != 0), (reduce_train.sum(axis=0) != 0)].columns # delete useless columns\n",
    "features = [x for x in features if x not in ['accuracy_group', 'installation_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove = [\n",
    "    '4d911100', 'Scrub_A_Dub_4010', 'e3ff61fb', '3120_g', '4235', '73757a5e', '5a848010', \n",
    "    '5f5b2617', '6f4adc4b', '6f8106d9', '56817e2b', '05ad839b', 'Leaf_Leader_4090', 'Happy_Camel_2000', \n",
    "    'Watering_Hole__Activity__5010', 'Slop_Problem_2000', '7961e599', '6f445b57', '86ba578b', '5000_A', \n",
    "    '4031_g', 'Cauldron_Filler__Assessment__2030', '88d4a5be', 'Bubble_Bath_4230', '2030_g', \n",
    "    'Mushroom_Sorter__Assessment__2000', 'Chicken_Balancer__Activity__4090', 'Crystals_Rule_2000', \n",
    "    '4110_g', 'Dino_Dive_2060', 'd3268efa', '3bfd1a65', '4095_g', '77ead60d', 'Dino_Drink_2060', \n",
    "    'a592d54e', 'Scrub_A_Dub_3121', 'ab3136ba', 'Scrub_A_Dub_2040', 'Pan_Balance_4010', '3110', \n",
    "    '5010_A', '4220_g', '16667cc5', 'Bubble_Bath_4045', 'Egg_Dropper__Activity__2020', 'cb6010f8', \n",
    "    'Egg_Dropper__Activity__2000', 'd88e8f25', 'Leaf_Leader_2070', '2070_g', 'Bug_Measurer__Activity__2000', \n",
    "    'cb1178ad', 'cf7638f3', 'Dino_Dive_4090', 'Cart_Balancer__Assessment__2000', 'd3640339', '83c6c409', \n",
    "    '7525289a', 'b80e5e84', 'Chow_Time_4090', '2060_g', 'Mushroom_Sorter__Assessment__4090', \n",
    "    'Scrub_A_Dub_3021', '71e712d8', 'ad148f58', 'Pan_Balance_4025', '85d1b0de', 'Watering_Hole__Activity__5000', \n",
    "    '2000_A', 'Bottle_Filler__Activity_', 'c51d8688', '9e4c8c7b', 'Dino_Dive_2070', 'Happy_Camel_4010', \n",
    "    'Leaf_Leader_3110', '4025_g', 'Crystals_Rule_4090', '2081_g', '4050_g', 'Air_Show_2060', \n",
    "    'Dino_Drink_2070', 'Chow_Time_4080', '7ad3efc6', 'a6d66e51', 'All_Star_Sorting_4010', '2000_g', \n",
    "    'Leaf_Leader_4010', 'Bubble_Bath_2080', '0d18d96c', 'Mushroom_Sorter__Assessment__2025', \n",
    "    'Watering_Hole__Activity__4090', 'Bubble_Bath_2025', '29bdd9ba', 'Cauldron_Filler__Assessment__4090', \n",
    "    '71fe8f75', '28ed704e', 'cc5087a3', '3110_g', '155f62a4', '3dcdda7f', '9b4001e4', 'd2e9262e', '6043a2b4', \n",
    "    '99ea62f3', 'Treasure_Map_2000', '06372577', 'Mushroom_Sorter__Assessment__4025', 'Bird_Measurer__Assessment__4080', \n",
    "    '3bf1cf26', 'a1192f43', 'd06f75b5', '6088b756', 'Cauldron_Filler__Assessment__4080', '37c53127', 'Bubble_Bath_2035', \n",
    "    'Dino_Drink_4031', '9de5e594', 'f5b8c21a', 'b74258a0', '2020_A', '2083_g', '4045_g', '38074c54', 'All_Star_Sorting_4095', \n",
    "    'e720d930', 'Pan_Balance_4090', '4e5fc6f5', 'Bubble_Bath_2000', 'Pan_Balance_2000', '2080_g', \n",
    "    'Bottle_Filler__Activity__4080', 'All_Star_Sorting_2025', 'Happy_Camel_2080', 'e4f1efe6', '3121', '0086365d', '2b9272f4', \n",
    "    'Dino_Drink_3021', 'Bubble_Bath_4010', 'Happy_Camel_2030', 'Fireworks__Activity__4090', 'Watering_Hole__Activity__2000', \n",
    "    'All_Star_Sorting_2000', 'Air_Show_3121', 'Crystals_Rule_3021', 'Bubble_Bath_4020', '6077cc36', '85de926c', 'bdf49a58', \n",
    "    'Happy_Camel_4095', 'a52b92d5', '2050_g', 'Mushroom_Sorter__Assessment__2020', 'Sandcastle_Builder__Activity__4090', \n",
    "    '7cf1bc53', 'b012cd7f', 'Flower_Waterer__Activity__4080', '731c0cbe', 'Scrub_A_Dub_2050', 'Dino_Drink_4090', '3b2048ee', \n",
    "    'ea321fb1', 'a5be6304', '93edfe2e', '3a4be871', '895865f3', 'e7e44842', 'Bird_Measurer__Assessment__2000', \n",
    "    'Bubble_Bath_4235', 'Crystals_Rule_4050', 'Bubble_Bath_2020', 'ea296733', '2050', '47f43a44', '86c924c4', \n",
    "    'Air_Show_4010', 'Dino_Drink_2000', 'c277e121', '27253bdc', 'Leaf_Leader_2060', 'bd701df8', 'Dino_Drink_2030', \n",
    "    'Cart_Balancer__Assessment__2030', '4010_g', 'Dino_Dive_4010', 'Leaf_Leader_4095', 'b5053438', '6f4bd64e', '4080_A', \n",
    "    'Bubble_Bath_3120', 'ad2fc29c', '08ff79ad', 'Leaf_Leader_3010', '2040_g', 'All_Star_Sorting_4090', 'Bubble_Bath_2083', \n",
    "    '2075_g', '7d5c30a2', '3323d7e9', 'Welcome_to_Lost_Lagoon_', '6cf7d25c', '4080_g', '4b5efe37', 'e5c9df6f', \n",
    "    'Bug_Measurer__Activity__4090', 'Cart_Balancer__Assessment__4090', 'Air_Show_3020', '2035_g', 'c74f40cd', \n",
    "    '3121_g', 'b2dba42b', 'Air_Show_3120', 'Happy_Camel_2020', 'e37a2b78', '4021_A', 'Dino_Drink_4010', '99abe2bb', \n",
    "    'e04fb33d', 'dcaede90', 'Flower_Waterer__Activity__4090', 'ca11f653', 'daac11b0', 'Cauldron_Filler__Assessment__2000', \n",
    "    'Mushroom_Sorter__Assessment__4035', '5de79a6a', '30df3273', 'Bubble_Bath_4095', '77c76bc5', 'Chest_Sorter__Assessment__4090', \n",
    "    'd45ed6a1', '8d748b58', 'installation_session_count', 'c6971acf', '15ba1109', 'Cart_Balancer__Assessment__2020', '65abac75', \n",
    "    '2030_A', 'a8a78786', '736f9581', '4022_A', 'Cart_Balancer__Assessment__2010', 'e9c52111', 'Egg_Dropper__Activity__4090', \n",
    "    'Crystals_Rule_3121', 'Crystals_Rule_4010', 'Bird_Measurer__Assessment__4035', 'Scrub_A_Dub_4090', '51311d7a', '250513af', \n",
    "    'Chicken_Balancer__Activity__2000', '5290eab1', '923afab1', 'Chicken_Balancer__Activity__4080', '5010', 'ecaab346', '90ea0bac', \n",
    "    '2230fab4', 'b7dc8128', 'e57dd7af', 'f28c589a', 'Bubble_Bath_2030', 'Bird_Measurer__Assessment__4090', 'Happy_Camel_4090', \n",
    "    'Sandcastle_Builder__Activity__4080', '19967db1', '3110_A', 'e5734469', 'Crystals_Rule_2030', 'd88ca108', 'Dino_Dive_2000', \n",
    "    '1996c610', 'f7e47413', '2010_A', '4080', '3120', 'Chest_Sorter__Assessment__2000', 'Cart_Balancer__Assessment__3121', \n",
    "    'Air_Show_2070', '67aa2ada', 'Chow_Time_2000', 'beb0a7b9', 'Happy_Camel_2081', 'Chest_Sorter__Assessment__2030', '33505eae', \n",
    "    'Leaf_Leader_2075', 'c7f7f0e1', '8d7e386c', '3bb91dda', '26a5a3dd', 'a29c5338', 'Cauldron_Filler__Assessment__3021', '15eb4a7d', \n",
    "    'bbfe0445', 'df4940d3', 'All_Star_Sorting_4080', '2030', 'Air_Show_2075', '1beb320a', 'Chest_Sorter__Assessment__2020', \n",
    "    'Bottle_Filler__Activity__4090', 'fd20ea40', '4235_g', '9554a50b', '5154fc30', 'c7fe2a55', 'Air_Show_3021', 'Air_Show_4090', \n",
    "    'c54cf6c5', 'Activity_sum_event_count', '26fd2d99', '4230_g', 'Leaf_Leader_2000', '92687c59', '3dfd4aa4', '47efca07', \n",
    "    'Air_Show_2000', '1340b8d7', '8b757ab8', 'Mushroom_Sorter__Assessment__2035', '8f094001', 'Chest_Sorter__Assessment__2010', '37ee8496'\n",
    "]\n",
    "\n",
    "counter = 0\n",
    "for feat_a in features:\n",
    "    for feat_b in features:\n",
    "        if feat_a != feat_b and feat_a not in to_remove and feat_b not in to_remove:\n",
    "            c = np.corrcoef(reduce_train[feat_a], reduce_train[feat_b])[0][1]\n",
    "            if c > 0.995:\n",
    "                counter += 1\n",
    "                to_remove.append(feat_b)\n",
    "                print('{}: FEAT_A: {} FEAT_B: {} - Correlation: {}'.format(counter, feat_a, feat_b, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_exclude = [] \n",
    "ajusted_test = reduce_test.copy()\n",
    "# for feature in ajusted_test.columns:\n",
    "#     if feature not in ['accuracy_group', 'installation_id', 'accuracy_group']+categoricals:\n",
    "#         data = reduce_train[feature]\n",
    "#         train_mean = data.mean()\n",
    "#         data = ajusted_test[feature] \n",
    "#         test_mean = data.mean()\n",
    "#         try:\n",
    "#             error = stract_hists(feature, adjust=True)\n",
    "#             ajust_factor = train_mean / test_mean\n",
    "#             if ajust_factor > 10 or ajust_factor < 0.1:# or error > 0.01:\n",
    "#                 to_exclude.append(feature)\n",
    "#                 print(feature, train_mean, test_mean, error)\n",
    "#             else:\n",
    "#                 ajusted_test[feature] *= ajust_factor\n",
    "#         except:\n",
    "#             to_exclude.append(feature)\n",
    "#             print(feature, train_mean, test_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals = [x for x in categoricals if x not in (to_exclude + to_remove)]\n",
    "features = [x for x in features if x not in (to_exclude + to_remove)]\n",
    "reduce_train[features].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_qwk_lgb_regr(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Fast cappa eval function for lgb.\n",
    "    \"\"\"\n",
    "    dist = Counter(reduce_train['accuracy_group'])\n",
    "    for k in dist:\n",
    "        dist[k] /= len(reduce_train)\n",
    "    reduce_train['accuracy_group'].hist()\n",
    "    \n",
    "    acum = 0\n",
    "    bound = {}\n",
    "    for i in range(3):\n",
    "        acum += dist[i]\n",
    "        bound[i] = np.percentile(y_pred, acum * 100)\n",
    "\n",
    "    def classify(x):\n",
    "        if x <= bound[0]:\n",
    "            return 0\n",
    "        elif x <= bound[1]:\n",
    "            return 1\n",
    "        elif x <= bound[2]:\n",
    "            return 2\n",
    "        else:\n",
    "            return 3\n",
    "\n",
    "    y_pred = np.array(list(map(classify, y_pred))).reshape(y_true.shape)\n",
    "\n",
    "    return 'cappa', cohen_kappa_score(y_true, y_pred, weights='quadratic'), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohenkappa(ypred, y):\n",
    "    y = y.get_label().astype(\"int\")\n",
    "    ypred = ypred.reshape((4, -1)).argmax(axis = 0)\n",
    "    loss = cohenkappascore(y, y_pred, weights = 'quadratic')\n",
    "    return \"cappa\", loss, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Base_Model(object):\n",
    "    \n",
    "    def __init__(self, train_df, test_df, features, categoricals=[], n_splits=5, cv_method='StratifiedKFold', verbose=True,ps={}):\n",
    "        self.train_df = train_df\n",
    "        self.test_df = test_df\n",
    "        self.features = features\n",
    "        self.n_splits = n_splits\n",
    "        self.categoricals = categoricals\n",
    "        self.target = 'accuracy_group'\n",
    "        self.cv = self.get_cv(cv_method)\n",
    "        self.verbose = verbose\n",
    "#         self.params = self.get_params()\n",
    "        self.params = self.set_params(ps)\n",
    "        self.oof_pred, self.y_pred, self.score, self.models = self.fit()\n",
    "        \n",
    "    def train_model(self, train_set, val_set):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def get_cv(self, cv_method):\n",
    "        method = cv_method\n",
    "        if method=='StratifiedKFold':\n",
    "            cv = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=42)\n",
    "            return cv.split(self.train_df, self.train_df[self.target])\n",
    "        elif method=='GroupKFold':\n",
    "            cv = GroupKFold(n_splits=self.n_splits)\n",
    "            return cv.split(self.train_df, self.train_df[self.target], self.train_df['installation_id'])\n",
    "    \n",
    "    def get_params(self):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def convert_dataset(self, x_train, y_train, x_val, y_val):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def convert_x(self, x):\n",
    "        return x\n",
    "        \n",
    "    def fit(self):\n",
    "        oof_pred = np.zeros((len(reduce_train), ))\n",
    "        y_pred = np.zeros((len(reduce_test), ))\n",
    "        models = []\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(self.cv):\n",
    "            x_train, x_val = self.train_df[self.features].iloc[train_idx], self.train_df[self.features].iloc[val_idx]\n",
    "            y_train, y_val = self.train_df[self.target][train_idx], self.train_df[self.target][val_idx]\n",
    "            train_set, val_set = self.convert_dataset(x_train, y_train, x_val, y_val)\n",
    "            model = self.train_model(train_set, val_set)\n",
    "            models.append(model)\n",
    "            \n",
    "            conv_x_val = self.convert_x(x_val)\n",
    "            oof_pred[val_idx] = model.predict(conv_x_val).reshape(oof_pred[val_idx].shape)\n",
    "            x_test = self.convert_x(self.test_df[self.features])\n",
    "            y_pred += model.predict(x_test).reshape(y_pred.shape) / self.n_splits\n",
    "            print('Partial score of fold {} is: {}'.format(fold, eval_qwk_lgb_regr(y_val, oof_pred[val_idx])[1]))\n",
    "        _, loss_score, _ = eval_qwk_lgb_regr(self.train_df[self.target], oof_pred)\n",
    "        if self.verbose:\n",
    "            print(f'\\nOur oof cohen kappa score is: {loss_score}\\n')\n",
    "        return oof_pred, y_pred, loss_score, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lgb_Model(Base_Model):\n",
    "    \n",
    "    def train_model(self, train_set, val_set):\n",
    "        verbosity = 100 if self.verbose else 0\n",
    "        return lgb.train(self.params, train_set, valid_sets=[train_set, val_set], verbose_eval=verbosity)\n",
    "        \n",
    "    def convert_dataset(self, x_train, y_train, x_val, y_val):\n",
    "        train_set = lgb.Dataset(x_train, y_train, categorical_feature=self.categoricals)\n",
    "        val_set = lgb.Dataset(x_val, y_val, categorical_feature=self.categoricals)\n",
    "        return train_set, val_set\n",
    "        \n",
    "    def get_params(self):\n",
    "        params = {\n",
    "            'n_estimators':5000,\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'regression',\n",
    "            'metric': 'rmse',\n",
    "            'subsample': 0.75,\n",
    "            'subsample_freq': 1,\n",
    "            'learning_rate': 0.01,\n",
    "            'feature_fraction': 0.9,\n",
    "            'max_depth': 15,\n",
    "            'lambda_l1': 1,  \n",
    "            'lambda_l2': 1,\n",
    "            'early_stopping_rounds': 100\n",
    "        }\n",
    "        return params\n",
    "    def set_params(self,ps={}):\n",
    "        params = self.get_params()\n",
    "        if 'subsample_freq' in ps:\n",
    "            params['subsample_freq']=int(ps['subsample_freq'])\n",
    "            params['learning_rate']=ps['learning_rate']\n",
    "            params['feature_fraction']=ps['feature_fraction']\n",
    "            params['lambda_l1']=ps['lambda_l1']\n",
    "            params['lambda_l2']=ps['lambda_l2']\n",
    "            params['max_depth']=int(ps['max_depth'])\n",
    "        \n",
    "        return params    \n",
    "    \n",
    "    def get_feature_importance(self, models):\n",
    "        feature_importance = pd.DataFrame(\n",
    "            [model.feature_importance() for model in models],\n",
    "            columns=models[0].feature_name()\n",
    "        ).T\n",
    "\n",
    "        feature_importance['Agerage_Importance'] = feature_importance.iloc[:, :len(models)].mean(axis=1)\n",
    "        feature_importance['importance_std'] = feature_importance.iloc[:, :len(models)].std(axis=1)\n",
    "        feature_importance.sort_values(by='Agerage_Importance', inplace=True)\n",
    "        return feature_importance\n",
    "    \n",
    "    def plot_importance(self, models, max_num_features=50, figsize=(12, 15)):\n",
    "        feature_importance = self.get_feature_importance(models)\n",
    "        plt.figure(figsize=figsize)\n",
    "        \n",
    "        feature_importance[-max_num_features:].plot(\n",
    "            kind='barh', title='Feature importance', figsize=figsize,\n",
    "            y='Agerage_Importance', xerr='importance_std',\n",
    "            grid=True, align=\"center\"\n",
    "        )\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Catb_Model(Base_Model):\n",
    "    \n",
    "    def train_model(self, train_set, val_set):\n",
    "        verbosity = 100 if self.verbose else 0\n",
    "        clf = CatBoostRegressor(**self.params)\n",
    "        clf.fit(train_set['X'], \n",
    "                train_set['y'], \n",
    "                eval_set=(val_set['X'], val_set['y']),\n",
    "                verbose=verbosity, \n",
    "                cat_features=self.categoricals)\n",
    "        return clf\n",
    "        \n",
    "    def convert_dataset(self, x_train, y_train, x_val, y_val):\n",
    "        train_set = {'X': x_train, 'y': y_train}\n",
    "        val_set = {'X': x_val, 'y': y_val}\n",
    "        return train_set, val_set\n",
    "        \n",
    "    def get_params(self):\n",
    "        params = {\n",
    "            'loss_function': 'RMSE',\n",
    "            'task_type': \"CPU\",\n",
    "            'iterations': 5000,\n",
    "            'od_type': \"Iter\",\n",
    "            'depth': 7,\n",
    "            'learning_rate': 0.3,\n",
    "            'subsample': 0.8,\n",
    "            'colsample_bylevel': 0.5, \n",
    "            'early_stopping_rounds': 300,\n",
    "            'l2_leaf_reg': 18,\n",
    "            'random_seed': 42,\n",
    "            'use_best_model': True\n",
    "        }\n",
    "        return params\n",
    "    \n",
    "    def set_params(self, ps={}):\n",
    "        return self.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LGB_Beyes(subsample_freq,\n",
    "                    learning_rate,\n",
    "                    feature_fraction,\n",
    "                    max_depth,\n",
    "                    lambda_l1,\n",
    "                    lambda_l2):\n",
    "    params={}\n",
    "    params['subsample_freq']=subsample_freq\n",
    "    params['learning_rate']=learning_rate\n",
    "    params['feature_fraction']=feature_fraction\n",
    "    params['lambda_l1']=lambda_l1\n",
    "    params['lambda_l2']=lambda_l2\n",
    "    params['max_depth']=max_depth\n",
    "    lgb_model = Lgb_Model(reduce_train, ajusted_test, features, categoricals=categoricals,ps=params)\n",
    "    print('kappa: ',lgb_model.score)\n",
    "    return lgb_model.score\n",
    "\n",
    "bounds_LGB = {\n",
    "    'subsample_freq': (1, 3),\n",
    "    'learning_rate': (0.025, 0.4),\n",
    "    'feature_fraction': (0.5, 1),\n",
    "    'lambda_l1': (1, 5),\n",
    "    'lambda_l2': (1, 5),\n",
    "    'max_depth': (15, 17),\n",
    "}\n",
    "\n",
    "if False and os.path.exists('/kaggle/input/data-science-bowl-2019/'):\n",
    "    LGB_BO = BayesianOptimization(LGB_Beyes, bounds_LGB, random_state=1029)\n",
    "    import warnings\n",
    "    init_points = 16\n",
    "    n_iter = 16\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings('ignore')\n",
    "        LGB_BO.maximize(init_points=init_points, n_iter=n_iter, acq='ucb', xi=0.0, alpha=1e-6)\n",
    "        \n",
    "    params = LGB_BO.max['params']\n",
    "    print('\\n', LGB_BO.max['params'])\n",
    "else:\n",
    "    params = {\n",
    "        'feature_fraction': 0.8,\n",
    "        'lambda_l1': 2, \n",
    "        'lambda_l2': 3, \n",
    "        'learning_rate': 0.03, \n",
    "        'num_leaves': 2**8,\n",
    "        'max_depth': 7, \n",
    "        'min_data_in_leaf': 50,\n",
    "        'subsample_freq': 1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_ensemble = False\n",
    "\n",
    "if is_ensemble:\n",
    "    cat_model = Catb_Model(reduce_train, ajusted_test, features, categoricals=categoricals)\n",
    "    lgb_model = Lgb_Model(reduce_train, ajusted_test, features, categoricals=categoricals, ps=params, cv_method='StratifiedKFold')\n",
    "    lgb_model_group = Lgb_Model(reduce_train, ajusted_test, features, categoricals=categoricals, ps=params, cv_method='GroupKFold')\n",
    "    # xgb_model = Xgb_Model(reduce_train, ajusted_test, features, categoricals=categoricals)\n",
    "else:\n",
    "    lgb_model = Lgb_Model(reduce_train, ajusted_test, features, categoricals=categoricals, ps=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model.plot_importance(lgb_model.models, max_num_features=100, figsize=(12, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1,1, figsize=(12, 24))\n",
    "# xgb.plot_importance(xgb_model.models[0], ax=ax, max_num_features=100, importance_type='weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "if is_ensemble:\n",
    "    off_df = pd.DataFrame({\n",
    "        'lbg': lgb_model.oof_pred, \n",
    "        'cat': cat_model.oof_pred, \n",
    "        'lgb_model_group': lgb_model_group.oof_pred\n",
    "    })\n",
    "    lr = LinearRegression().fit(off_df, reduce_train['accuracy_group'])\n",
    "    \n",
    "    weights = {c: w for c, w in zip(off_df.columns, lr.coef_)}\n",
    "    print(weights, '\\n')\n",
    "    final_pred = (lgb_model.y_pred * weights['lbg']) + (cat_model.y_pred * weights['cat']) + (lgb_model_group.y_pred * weights['lgb_model_group'])\n",
    "    # final_pred = (lgb_model.y_pred * weights['lbg']) + (cat_model.y_pred * weights['cat']) + (xgb_model.y_pred * weights['xgb'])\n",
    "    trian_pred_reg = lr.predict(off_df)\n",
    "else:\n",
    "    final_pred = lgb_model.y_pred\n",
    "    trian_pred_reg = lgb_model.oof_pred\n",
    "\n",
    "print(final_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# improved\n",
    "import scipy as sp\n",
    "from functools import partial\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "class OptimizedRounder(object):\n",
    "    \"\"\"\n",
    "    An optimizer for rounding thresholds\n",
    "    to maximize Quadratic Weighted Kappa (QWK) score\n",
    "    # https://www.kaggle.com/naveenasaithambi/optimizedrounder-improved\n",
    "    \"\"\"\n",
    "    def __init__(self, num_class=4):\n",
    "        self.coef_ = 0\n",
    "        self.initial_coef = [i for i in np.arange(1, (num_class+1)/2, 0.5)]\n",
    "        self.labels = [i for i in range(num_class)]\n",
    "    \n",
    "    def _kappa_loss(self, coef, X, y):\n",
    "        \"\"\"\n",
    "        Get loss according to\n",
    "        using current coefficients\n",
    "        \n",
    "        :param coef: A list of coefficients that will be used for rounding\n",
    "        :param X: The raw predictions\n",
    "        :param y: The ground truth labels\n",
    "        \"\"\"\n",
    "        preds = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels=self.labels)\n",
    "        return -cohen_kappa_score(y, preds, weights = 'quadratic')\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Optimize rounding thresholds\n",
    "        \n",
    "        :param X: The raw predictions\n",
    "        :param y: The ground truth labels\n",
    "        \"\"\"\n",
    "        loss_partial = partial(self._kappa_loss, X = X, y = y)\n",
    "        initial_coef = self.initial_coef\n",
    "        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method = 'nelder-mead')\n",
    "    \n",
    "    def predict(self, X, coef):\n",
    "        \"\"\"\n",
    "        Make predictions with specified thresholds\n",
    "        \n",
    "        :param X: The raw predictions\n",
    "        :param coef: A list of coefficients that will be used for rounding\n",
    "        \"\"\"\n",
    "        preds = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels=self.labels)\n",
    "        return preds\n",
    "    \n",
    "    def coefficients(self):\n",
    "        \"\"\"\n",
    "        Return the optimized coefficients\n",
    "        \"\"\"\n",
    "        return self.coef_['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optR = OptimizedRounder(num_class=4)\n",
    "optR.fit(trian_pred_reg, reduce_train['accuracy_group'])\n",
    "coefficients = optR.coefficients()\n",
    "\n",
    "opt_preds = optR.predict(trian_pred_reg.reshape(-1, ), coefficients)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "rmse_score = np.sqrt(mean_squared_error(reduce_train['accuracy_group'], lgb_model.oof_pred))\n",
    "print(f'\\nrmse_score is {rmse_score}\\n')\n",
    "\n",
    "off_score = cohen_kappa_score(reduce_train['accuracy_group'], opt_preds, weights='quadratic')\n",
    "print(f'off_score is {off_score}\\n')\n",
    "\n",
    "print(f'coefficients is \\n{coefficients}\\n')\n",
    "\n",
    "sample_submission['accuracy_group'] = optR.predict(final_pred.reshape(-1, ), coefficients).astype(int)\n",
    "sample_submission.to_csv('submission.csv', index=False)\n",
    "display(sample_submission['accuracy_group'].value_counts(normalize=True).sort_index())\n",
    "sample_submission['accuracy_group'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "result_scores = []\n",
    "_smpl_train = []\n",
    "_smpl_pred = []\n",
    "\n",
    "def f():\n",
    "    actual = reduce_train['accuracy_group'].copy()\n",
    "    preds = pd.Series(opt_preds)\n",
    "    for i in range(4):\n",
    "        _smpl_train.extend(actual[actual==i].sample(100))\n",
    "        _smpl_pred.extend(preds[actual==i].sample(100))\n",
    "    return cohen_kappa_score(_smpl_train, _smpl_pred, weights='quadratic')\n",
    "\n",
    "result_scores = Parallel(n_jobs=-1, verbose=0)( [delayed(f)() for i in range(1000)] )\n",
    "\n",
    "print(f'off_score is {off_score}\\n')\n",
    "pd.Series(result_scores).describe().round(3).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(y_true, y_pred, figsize=(8, 8)):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=np.unique(y_true))\n",
    "    cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
    "    cm_perc = cm / cm_sum.astype(float) * 100\n",
    "    annot = np.empty_like(cm).astype(str)\n",
    "    nrows, ncols = cm.shape\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            c = cm[i, j]\n",
    "            p = cm_perc[i, j]\n",
    "            if i == j:\n",
    "                s = cm_sum[i]\n",
    "                annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n",
    "            elif c == 0:\n",
    "                annot[i, j] = ''\n",
    "            else:\n",
    "                annot[i, j] = '%.1f%%\\n%d' % (p, c)\n",
    "    cm = pd.DataFrame(cm, index=np.unique(y_true), columns=np.unique(y_true))\n",
    "    cm.index.name = 'Actual'\n",
    "    cm.columns.name = 'Predicted'\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    sns.heatmap(cm, cmap=plt.cm.Blues, square=True, annot=annot, fmt='', ax=ax)\n",
    "\n",
    "\n",
    "plt.title('Result')\n",
    "reduce_train['accuracy_group'].hist(align='left', rwidth=0.4, color='tab:orange', label='actual')\n",
    "pd.Series(opt_preds).hist(align='mid', rwidth=0.4, color='tab:blue', label='predict')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plot_cm(reduce_train['accuracy_group'], opt_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# smpl_scores = []\n",
    "# valid_scores = []\n",
    "# for i in range(100):\n",
    "#     _trian, _smpl_train, _pred, _smpl_pred = train_test_split(\n",
    "#         reduce_train['accuracy_group'], opt_preds.tolist(), test_size=0.14, random_state=42+i)\n",
    "    \n",
    "#     smpl_scores.append(cohen_kappa_score(_smpl_train[:140], _smpl_pred[:140], weights='quadratic'))\n",
    "#     valid_scores.append(cohen_kappa_score(_trian[:860], _pred[:860], weights='quadratic'))\n",
    "\n",
    "# pd.DataFrame({'smpl': smpl_scores, 'valid': valid_scores}).describe().round(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "16c15db6f6254e71acc9b95016283200": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "1a3c05de029b4175a26225cbb194f3c8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "27bb6561b1544eebb9cfd7b4f2c7ca0f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6ff00c5524a74e36834f9c394bc9e550",
       "placeholder": "​",
       "style": "IPY_MODEL_3ec4aa5ca6994e06ad4994e29b3be796",
       "value": " 1000/1000 [02:25&lt;00:00,  6.88it/s]"
      }
     },
     "3140aa7101094a2ab498c33126c2e160": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3ec4aa5ca6994e06ad4994e29b3be796": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "55919e11c6c04441a14c348b46187ba9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "6b6f58ab735e40c88d804d33da718fa7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6d42bbb6ca114fe2bfb7c599f8878be3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3140aa7101094a2ab498c33126c2e160",
       "max": 17000,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_55919e11c6c04441a14c348b46187ba9",
       "value": 17000
      }
     },
     "6ff00c5524a74e36834f9c394bc9e550": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8453bb3bc2a34d90a51c787224debe35": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e9afc751d1994c48af0764907308ea75",
        "IPY_MODEL_27bb6561b1544eebb9cfd7b4f2c7ca0f"
       ],
       "layout": "IPY_MODEL_1a3c05de029b4175a26225cbb194f3c8"
      }
     },
     "9446846a28ef4d8db9392f1fcf24d774": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6d42bbb6ca114fe2bfb7c599f8878be3",
        "IPY_MODEL_ed849081b5bf4605a594778a2edbf548"
       ],
       "layout": "IPY_MODEL_dca885bb19a8492d802df0bd42a413e1"
      }
     },
     "be9af6bee8044790889a5cfcedf52367": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c5f62c223b6a410ebde8de79c163d640": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "dca885bb19a8492d802df0bd42a413e1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e9afc751d1994c48af0764907308ea75": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_be9af6bee8044790889a5cfcedf52367",
       "max": 1000,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c5f62c223b6a410ebde8de79c163d640",
       "value": 1000
      }
     },
     "ed849081b5bf4605a594778a2edbf548": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6b6f58ab735e40c88d804d33da718fa7",
       "placeholder": "​",
       "style": "IPY_MODEL_16c15db6f6254e71acc9b95016283200",
       "value": " 17000/17000 [10:34&lt;00:00, 26.79it/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
